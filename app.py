import json
import re
import streamlit as st
import pandas as pd
from src.agent.agent_orquestrador import criar_orquestrador
from src.agent.config_agent import Settings
from src.data.bases import download_base
from src.agent.eda_utils import analise_eda_completa
from src.util.utils import gerar_hash_df_leve
from langchain_groq import ChatGroq
import matplotlib.pyplot as plt
import traceback
from datetime import datetime
import io
import zipfile

# =============================================================================
# CONFIGURAÃ‡ÃƒO INICIAL
# =============================================================================

st.set_page_config(
    page_title="ğŸ¤– EDA Inteligente - AnÃ¡lise de CSV com IA", 
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://github.com/seu-usuario/seu-repo',
        'Report a bug': "https://github.com/seu-usuario/seu-repo/issues",
        'About': "Sistema EDA usando LangGraph e IA - Trabalha com qualquer CSV"
    }
)

# =============================================================================
# FUNÃ‡Ã•ES DE CARREGAMENTO DE DADOS
# =============================================================================

def clean_dataframe_for_streamlit(df):
    """
    Limpa o DataFrame para compatibilidade com Streamlit/PyArrow
    """
    df_clean = df.copy()
    
    try:
        # Converter tipos problemÃ¡ticos
        for col in df_clean.columns:
            # Verificar se Ã© uma coluna problemÃ¡tica
            if df_clean[col].dtype == 'object':
                # Tentar converter para numÃ©rico se possÃ­vel
                try:
                    # Se todos os valores nÃ£o-nulos sÃ£o nÃºmeros, converter
                    pd.to_numeric(df_clean[col], errors='raise')
                    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')
                except:
                    # Se nÃ£o conseguir converter, manter como string
                    df_clean[col] = df_clean[col].astype(str)
            
            # Lidar com tipos Int64 problemÃ¡ticos
            elif str(df_clean[col].dtype) in ['Int64', 'int64']:
                # Converter para int32 ou float se houver NaNs
                if df_clean[col].isna().any():
                    df_clean[col] = df_clean[col].astype('float64')
                else:
                    try:
                        df_clean[col] = df_clean[col].astype('int32')
                    except:
                        df_clean[col] = df_clean[col].astype('float64')
            
            # Converter boolean nullable para bool padrÃ£o
            elif str(df_clean[col].dtype) == 'boolean':
                df_clean[col] = df_clean[col].astype('bool')
        
        return df_clean
    
    except Exception as e:
        # Se a limpeza falhar, converter tudo para string como Ãºltimo recurso
        print(f"Erro na limpeza, convertendo para strings: {e}")
        for col in df_clean.columns:
            df_clean[col] = df_clean[col].astype(str)
        return df_clean


def load_csv_file(uploaded_file):
    """Carrega arquivo CSV uploaded"""
    try:
        # Reset do ponteiro do arquivo
        uploaded_file.seek(0)
        
        # Verificar se Ã© um arquivo zip
        if uploaded_file.name.endswith('.zip'):
            with zipfile.ZipFile(uploaded_file, 'r') as zip_ref:
                # Listar arquivos no zip
                file_list = zip_ref.namelist()
                csv_files = [f for f in file_list if f.endswith('.csv')]
                
                if not csv_files:
                    st.error("âŒ Nenhum arquivo CSV encontrado no ZIP")
                    return None
                
                # Se houver mÃºltiplos CSVs, deixar o usuÃ¡rio escolher
                if len(csv_files) > 1:
                    selected_file = st.selectbox(
                        "ğŸ“ MÃºltiplos CSVs encontrados. Selecione um:",
                        csv_files
                    )
                else:
                    selected_file = csv_files[0]
                
                # Ler o CSV selecionado
                with zip_ref.open(selected_file) as csv_file:
                    df = pd.read_csv(csv_file)
                    
        else:
            # Arquivo CSV direto - tentar diferentes configuraÃ§Ãµes
            encodings_to_try = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']
            df = None
            
            for encoding in encodings_to_try:
                try:
                    # Reset do ponteiro antes de cada tentativa
                    uploaded_file.seek(0)
                    
                    # Primeiro, tentar ler normalmente
                    try:
                        df = pd.read_csv(uploaded_file, encoding=encoding)
                        break
                    except:
                        # Se falhar, tentar sem header (caso a primeira linha seja dados)
                        uploaded_file.seek(0)
                        df = pd.read_csv(uploaded_file, encoding=encoding, header=None)
                        
                        # Gerar nomes de colunas se nÃ£o houver header
                        df.columns = [f'Column_{i+1}' for i in range(len(df.columns))]
                        st.info(f"ğŸ“‹ Arquivo carregado sem cabeÃ§alhos. Colunas nomeadas como: {', '.join(df.columns)}")
                        break
                        
                except UnicodeDecodeError:
                    continue
                except Exception as e:
                    # Log do erro mas continue tentando
                    st.warning(f"Tentativa com encoding {encoding} falhou: {str(e)}")
                    continue
            
            if df is None:
                st.error("âŒ NÃ£o foi possÃ­vel ler o arquivo CSV com nenhum encoding testado.")
                return None
        
        # Validar se o DataFrame foi carregado corretamente
        if df is None or df.empty:
            st.error("âŒ DataFrame carregado estÃ¡ vazio")
            return None
        
        # Verificar se as colunas tÃªm nomes estranhos (apenas nÃºmeros)
        if all(str(col).isdigit() or col == 0 for col in df.columns):
            st.warning("âš ï¸ Detectadas colunas com nomes numÃ©ricos. Possivelmente o arquivo nÃ£o tem cabeÃ§alhos apropriados.")
            # Renomear colunas para algo mais legÃ­vel
            df.columns = [f'Feature_{i+1}' for i in range(len(df.columns))]
            st.info(f"ğŸ”„ Colunas renomeadas para: {', '.join(df.columns)}")
        
        # NOVO: Limpar DataFrame para compatibilidade com Streamlit
        df_clean = clean_dataframe_for_streamlit(df)
        
        st.session_state["intermediate_results"] = {}
        # st.session_state["intermediate_results"]["analise_eda"] = eda_resultados
        # Log de sucesso com informaÃ§Ãµes bÃ¡sicas
        st.success(f"ğŸ“Š Dataset carregado com sucesso: {df_clean.shape[0]} linhas x {df_clean.shape[1]} colunas")
        
        return df_clean
        
    except Exception as e:
        st.error(f"âŒ Erro crÃ­tico ao carregar arquivo: {str(e)}")
        st.error("ğŸ’¡ Verifique se o arquivo Ã© um CSV vÃ¡lido")
        
        # Debug adicional
        st.error("ğŸ” InformaÃ§Ãµes de debug:")
        st.code(f"Erro: {type(e).__name__}: {str(e)}")
        return None

@st.cache_data
def get_default_dataframe():
    try:
        df = download_base()
        
        return df
    except Exception as e:
        st.warning(f"âš ï¸ NÃ£o foi possÃ­vel carregar dataset padrÃ£o: {e}")
        return pd.DataFrame()

@st.cache_resource
def get_llm():
    """Inicializa o LLM uma Ãºnica vez com configuraÃ§Ãµes otimizadas"""
    try:
        return ChatGroq(
            temperature=0,
            # groq_api_key=Settings.GROQ_API_KEY,
            model=Settings.LLM_MODEL,
            max_tokens=4096,
            timeout=60  # Timeout maior para anÃ¡lises complexas
        )
    except Exception as e:
        st.error(f"âŒ Erro ao inicializar LLM: {e}")
        return None

@st.cache_resource
def get_orchestrator(_llm, _df_hash):
    """Cria o orquestrador com base no hash do DataFrame"""
    if _llm is None or _df_hash is None:
        return None
    try:
        # Usar o hash para garantir que o cache seja invalidado quando o DF mudar
        return criar_orquestrador(_llm, st.session_state.current_df)
    except Exception as e:
        st.error(f"âŒ Erro ao criar orquestrador: {e}")
        return None

# =============================================================================
# INICIALIZAÃ‡ÃƒO DE ESTADO
# =============================================================================

# Inicializar LLM
llm = get_llm()

# Inicializar estado da sessÃ£o - COMEÃ‡AR VAZIO
if "messages" not in st.session_state:
    st.session_state.messages = []

if "total_queries" not in st.session_state:
    st.session_state.total_queries = 0

if "session_start" not in st.session_state:
    st.session_state.session_start = datetime.now()

# MODIFICAÃ‡ÃƒO: Inicializar com DataFrame vazio
if "current_df" not in st.session_state:
    st.session_state.current_df = pd.DataFrame()  # ComeÃ§a vazio

if "dataset_name" not in st.session_state:
    st.session_state.dataset_name = None  # ComeÃ§a sem dataset

if "analysis_history" not in st.session_state:
    st.session_state.analysis_history = []

# =============================================================================
# INTERFACE PRINCIPAL
# =============================================================================

st.title("ğŸ¤– EDA Inteligente - AnÃ¡lise de CSV com IA")
st.markdown("*Sistema genÃ©rico para anÃ¡lise exploratÃ³ria de qualquer arquivo CSV*")

# =============================================================================
# SEÃ‡ÃƒO DE CARREGAMENTO DE DADOS
# =============================================================================

st.header("ğŸ“ Carregamento de Dados")

# Exibir instruÃ§Ãµes se nÃ£o houver dataset carregado
if st.session_state.current_df.empty:
    st.info("ğŸ‘‹ **Bem-vindo ao Sistema EDA Inteligente!**\n\nPara comeÃ§ar, carregue um arquivo CSV ou use o dataset padrÃ£o abaixo.")

col1, col2 = st.columns([3, 1])

with col1:
    uploaded_file = st.file_uploader(
        "ğŸ”„ Carregue seu arquivo CSV",
        type=['csv'],
        help="Suporta arquivos CSV. O sistema analisarÃ¡ qualquer estrutura de dados."
    )

with col2:
    use_default = st.button("ğŸ“Š Usar Dataset PadrÃ£o", width="stretch")

# Processar carregamento de arquivo
if uploaded_file is not None:
    # Mostrar informaÃ§Ãµes do arquivo antes do processamento
    st.write("**InformaÃ§Ãµes do arquivo:**")
    st.write(f"- Nome: {uploaded_file.name}")
    st.write(f"- Tamanho: {uploaded_file.size:,} bytes ({uploaded_file.size/1024:.1f} KB)")
    st.write(f"- Tipo: {uploaded_file.type}")
    
    # Verificar se o arquivo nÃ£o Ã© muito grande (limite de 50MB)
    if uploaded_file.size > 50 * 1024 * 1024:
        st.warning("âš ï¸ Arquivo muito grande (>50MB). O carregamento pode ser lento.")
    
    # Usar progress bar
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        status_text.text("ğŸ” Iniciando carregamento...")
        progress_bar.progress(10)
        
        status_text.text("ğŸ“ˆ Processando arquivo CSV...")
        progress_bar.progress(30)
        
        new_df = load_csv_file(uploaded_file)
        progress_bar.progress(70)
        
        if new_df is not None:
            status_text.text("âœ… Validando dados...")
            progress_bar.progress(90)
            
            # Debug: verificar se o DataFrame foi carregado
            st.write(f"**DataFrame processado:** {new_df.shape[0]} linhas x {new_df.shape[1]} colunas")
            st.write(f"**Colunas encontradas:** {new_df.columns.tolist()}")
            
            # Atualizar estado da sessÃ£o
            st.session_state.current_df = new_df
            st.session_state.dataset_name = uploaded_file.name
            st.session_state.messages = []  # Limpar histÃ³rico ao carregar novo dataset
            st.session_state.analysis_history = []
            
            progress_bar.progress(100)
            status_text.text("âœ… Carregamento concluÃ­do!")
            
            st.success(f"Arquivo '{uploaded_file.name}' carregado com sucesso!")
            
            # Mostrar preview dos dados
            with st.expander("ğŸ‘€ Preview dos dados carregados", expanded=True):
                try:
                    # Mostrar apenas informaÃ§Ãµes bÃ¡sicas se houver problemas de exibiÃ§Ã£o
                    st.write(f"**Shape:** {new_df.shape[0]} linhas Ã— {new_df.shape[1]} colunas")
                    st.write(f"**Colunas:** {', '.join(new_df.columns.tolist()[:10])}{'...' if len(new_df.columns) > 10 else ''}")
                    
                    # Tentar mostrar o dataframe, com fallback para informaÃ§Ãµes bÃ¡sicas
                    try:
                        st.dataframe(new_df.head(), width="stretch")
                    except Exception as display_error:
                        st.warning(f"âš ï¸ NÃ£o foi possÃ­vel exibir o preview visual: {display_error}")
                        st.write("**Primeiras 5 linhas (formato texto):**")
                        st.text(str(new_df.head()))
                    
                    # InformaÃ§Ãµes dos tipos de dados
                    st.write("**Tipos de dados:**")
                    for col, dtype in new_df.dtypes.items():
                        st.write(f"- **{col}**: {str(dtype)}")
                        
                except Exception as preview_error:
                    st.error(f"Erro no preview: {preview_error}")
                    st.write("Arquivo carregado, mas preview nÃ£o disponÃ­vel.")
            
            # # ForÃ§ar atualizaÃ§Ã£o da interface
            # import time
            # time.sleep(0.5)  # Pequena pausa para garantir que tudo foi processado
            # st.rerun()
            
        else:
            progress_bar.progress(100)
            status_text.text("âŒ Falha no carregamento")
            st.error("âŒ NÃ£o foi possÃ­vel carregar o arquivo")
            st.info("ğŸ’¡ Tente verificar se o arquivo estÃ¡ no formato CSV correto")
    
    except Exception as e:
        progress_bar.progress(100)
        status_text.text("âŒ Erro no processamento")
        st.error(f"Erro inesperado: {str(e)}")
        st.code(f"Erro tÃ©cnico: {type(e).__name__}: {str(e)}")
    
    finally:
        # Limpar progress bar apÃ³s 2 segundos
        import time
        time.sleep(2)
        progress_bar.empty()
        status_text.empty()

# Usar dataset padrÃ£o
if use_default:
    default_df = get_default_dataframe()
    if not default_df.empty:
        st.session_state.current_df = default_df
        st.session_state.dataset_name = "Dataset PadrÃ£o (Credit Card Fraud)"
        st.session_state.messages = []
        st.session_state.analysis_history = []
        st.success("âœ… Dataset padrÃ£o carregado!")
        st.rerun()

# Obter DataFrame atual
df = st.session_state.current_df
# 99999999
if "current_df" in st.session_state:
    df = st.session_state.current_df

    if df is not None and not df.empty and len(df.columns) > 0:
        current_hash = gerar_hash_df_leve(df)

        if ("eda_summary" not in st.session_state) or (st.session_state.get("eda_hash") != current_hash):
            st.session_state.eda_summary = analise_eda_completa(df)
            st.session_state.eda_hash = current_hash
            st.success("âœ… Resumo EDA gerado/atualizado!")

        # st.write(st.session_state.eda_summary)
    else:
        st.warning("âš ï¸ DataFrame estÃ¡ vazio ou nÃ£o possui colunas.")
else:
    st.warning("ğŸ“‚ Nenhum DataFrame carregado ainda.")


# =============================================================================
# VALIDAÃ‡ÃƒO E CRIAÃ‡ÃƒO DO ORQUESTRADOR
# =============================================================================

# Criar hash do DataFrame para cache - apenas se nÃ£o estiver vazio
df_hash = None
if not df.empty:
    df_hash = hash(str(df.shape) + str(df.columns.tolist()) + str(df.iloc[0].tolist() if len(df) > 0 else []))

graph = get_orchestrator(llm, df_hash) if llm is not None and not df.empty else None

# =============================================================================
# SIDEBAR - MOSTRAR APENAS SE HOUVER DATASET
# =============================================================================

with st.sidebar:
    if not df.empty and st.session_state.dataset_name:
        st.header("ğŸ“Š InformaÃ§Ãµes do Dataset")
        st.write(f"**Dataset Atual:** {st.session_state.dataset_name}")
        
        # InformaÃ§Ãµes bÃ¡sicas
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ğŸ“ Linhas", f"{df.shape[0]:.0f}")
        with col2:
            st.metric("ğŸ“‹ Colunas", df.shape[1])
        
        # Tipos de dados detalhados
        st.subheader("ğŸ·ï¸ AnÃ¡lise de Tipos")
        numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
        datetime_cols = df.select_dtypes(include=['datetime']).columns.tolist()
        
        if numeric_cols:
            st.write(f"ğŸ”¢ **NumÃ©ricas ({len(numeric_cols)}):**")
            for col in numeric_cols[:5]:  # Mostrar apenas 5
                st.write(f"  â€¢ {col}")
            if len(numeric_cols) > 5:
                st.write(f"  ... e mais {len(numeric_cols) - 5}")
        
        if categorical_cols:
            st.write(f"ğŸ“ **CategÃ³ricas ({len(categorical_cols)}):**")
            for col in categorical_cols[:5]:
                st.write(f"  â€¢ {col}")
            if len(categorical_cols) > 5:
                st.write(f"  ... e mais {len(categorical_cols) - 5}")
        
        if datetime_cols:
            st.write(f"ğŸ“… **Data/Hora ({len(datetime_cols)}):**")
            for col in datetime_cols:
                st.write(f"  â€¢ {col}")
        
        # AnÃ¡lise de qualidade
        st.subheader("ğŸ” Qualidade dos Dados")
        null_counts = df.isnull().sum().sum()
        duplicate_counts = df.duplicated().sum()
        
        # MÃ©tricas de VariaÃ§Ã£o/Unicidade
        constant_cols_count = (df.nunique() == 1).sum()
        avg_cardinality = df.nunique().mean()
            
        if null_counts > 0:
            st.warning(f"âš ï¸ {null_counts:,} valores nulos ({(null_counts/df.size*100):.1f}%)")
        else:
            st.success("âœ… Sem valores nulos")
        
        if duplicate_counts > 0:
            st.warning(f"ğŸ”„ {duplicate_counts:,} linhas duplicadas")
        else:
            st.success("âœ… Sem duplicadas")

        if constant_cols_count > 0:
            st.warning(f"âš ï¸ {constant_cols_count:,} colunas sem variaÃ§Ã£o")
        else:
            st.success("âœ… Todas as colunas tÃªm variaÃ§Ã£o")
        
        st.info(f"ğŸ“ˆ Cardinalidade mÃ©dia: {avg_cardinality:.1f}")

        # Uso de memÃ³ria
        memory_usage = df.memory_usage(deep=True).sum() / 1024**2
        if memory_usage > 100:
            st.error(f"ğŸ’¾ {memory_usage:.1f} MB (Alto)")
        elif memory_usage > 10:
            st.warning(f"ğŸ’¾ {memory_usage:.1f} MB (MÃ©dio)")
        else:
            st.success(f"ğŸ’¾ {memory_usage:.1f} MB (Baixo)")
        
        # EstatÃ­sticas da sessÃ£o
        st.divider()
        st.subheader("ğŸ“ˆ EstatÃ­sticas da SessÃ£o")
        st.write(f"ğŸ”¢ Consultas realizadas: {st.session_state.total_queries}")
        st.write(f"ğŸ“‹ AnÃ¡lises no histÃ³rico: {len(st.session_state.analysis_history)}")
        
        duration = datetime.now() - st.session_state.session_start
        minutes = duration.seconds // 60
        seconds = duration.seconds % 60
        st.write(f"â±ï¸ Tempo de sessÃ£o: {minutes}min {seconds}s")
        
    else:
        # Estado inicial - sem dataset
        st.header("ğŸš€ Comece Aqui!")
        st.write("**Para usar o sistema:**")
        st.write("1. ğŸ“¤ Carregue um arquivo CSV")
        st.write("2. ğŸ“Š Ou use o dataset padrÃ£o")
        st.write("3. ğŸ’¬ FaÃ§a perguntas sobre os dados")
        
        st.divider()
        st.subheader("ğŸ¯ O que vocÃª pode fazer:")
        st.write("â€¢ AnÃ¡lise exploratÃ³ria automatizada")
        st.write("â€¢ DetecÃ§Ã£o de outliers e anomalias") 
        st.write("â€¢ CorrelaÃ§Ãµes e relaÃ§Ãµes")
        st.write("â€¢ VisualizaÃ§Ãµes inteligentes")
        st.write("â€¢ Insights e conclusÃµes")
        st.write("â€¢ Machine Learning")
    
    # Status do sistema - sempre mostrar
    st.divider()
    st.subheader("ğŸ”§ Status do Sistema")
    
    status_llm = "âœ…" if llm else "âŒ"
    status_data = "âœ…" if not df.empty else "â³"
    status_graph = "âœ…" if graph else "â³"
    
    st.write(f"{status_llm} LLM (Groq)")
    st.write(f"{status_data} Dataset")
    st.write(f"{status_graph} Orquestrador")

# =============================================================================
# VALIDAÃ‡ÃƒO DO SISTEMA - MOSTRAR APENAS SE TENTATIVA DE USO SEM DATASET
# =============================================================================

# Verificar se o sistema estÃ¡ pronto para anÃ¡lises
system_ready = all([llm, not df.empty, graph])

# Se nÃ£o hÃ¡ dataset carregado, mostrar instruÃ§Ã£o amigÃ¡vel
if df.empty:
    st.warning("ğŸ“‹ **Aguardando carregamento de dados**")
    st.info("Carregue um arquivo CSV ou use o dataset padrÃ£o para comeÃ§ar a anÃ¡lise.")
    
    # Mostrar preview do que estÃ¡ disponÃ­vel
    with st.expander("ğŸ” Preview das Funcionalidades DisponÃ­veis"):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            **ğŸ“Š AnÃ¡lise Descritiva**
            - Tipos de dados
            - EstatÃ­sticas descritivas
            - DistribuiÃ§Ãµes
            - Valores Ãºnicos
            """)
        
        with col2:
            st.markdown("""
            **ğŸ“ˆ VisualizaÃ§Ãµes**
            - Histogramas
            - Boxplots
            - CorrelaÃ§Ãµes
            - Scatter plots
            """)
        
        with col3:
            st.markdown("""
            **ğŸ§  Insights**
            - DetecÃ§Ã£o de outliers
            - PadrÃµes temporais
            - ConclusÃµes automÃ¡ticas
            - RecomendaÃ§Ãµes
            """)
    
    st.stop()  # Parar aqui se nÃ£o hÃ¡ dataset

# Se hÃ¡ problemas no sistema com dataset carregado
if not system_ready and not df.empty:
    st.error("âŒ Sistema nÃ£o estÃ¡ pronto para uso")
    
    if llm is None:
        st.error("ğŸ”§ **LLM nÃ£o inicializado** - Verifique a chave API do Groq")
    
    if graph is None:
        st.error("ğŸ”€ **Orquestrador nÃ£o criado** - Verifique as dependÃªncias")
    
    st.info("ğŸ’¡ Corrija os problemas acima para continuar")
    st.stop()

# =============================================================================
# ÃREA DO CHAT INTELIGENTE - APENAS SE DATASET CARREGADO
# =============================================================================

st.header("ğŸ’¬ Chat Inteligente para EDA")

# Container para as mensagens do chat
chat_container = st.container()

with chat_container:
    # Exibir histÃ³rico de mensagens
    for i, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # Mostrar timestamp para anÃ¡lises importantes
            if message["role"] == "assistant" and len(message["content"]) > 200:
                st.caption(f"ğŸ•’ AnÃ¡lise #{i//2 + 1}")

# =============================================================================
# SUGESTÃ•ES INTELIGENTES BASEADAS NOS DADOS
# =============================================================================

# if not st.session_state.messages and not df.empty:  # Apenas se nÃ£o houver histÃ³rico e houver dataset
#     st.info("ğŸ’¡ **SugestÃµes baseadas no seu dataset:**")
    
#     suggestions = []
    
#     # SugestÃµes baseadas na estrutura dos dados
#     # Para datasets com muitas colunas numÃ©ricas
#     numeric_cols = df.select_dtypes(include=['number']).columns
#     if len(numeric_cols) > 5:
#         suggestions.append("ğŸ“Š FaÃ§a uma anÃ¡lise descritiva completa dos dados")
#         suggestions.append("ğŸ”— Analise a correlaÃ§Ã£o entre as variÃ¡veis numÃ©ricas")
    
#     # Para datasets com variÃ¡vel target aparente
#     if any('class' in col.lower() for col in df.columns):
#         suggestions.append("ğŸ¯ Analise a distribuiÃ§Ã£o da variÃ¡vel target (class)")
#         suggestions.append("ğŸ” Identifique padrÃµes relacionados Ã  classificaÃ§Ã£o")
    
#     # Para datasets temporais
#     if any('time' in col.lower() or 'date' in col.lower() for col in df.columns):
#         suggestions.append("ğŸ“ˆ Analise padrÃµes temporais nos dados")
    
#     # Para detecÃ§Ã£o de anomalias
#     if len(df) > 1000:
#         suggestions.append("ğŸš¨ Detecte outliers e anomalias nos dados")
    
#     # SugestÃµes gerais
#     suggestions.extend([
#         "ğŸ“‹ Descreva os tipos de dados e estrutura do dataset",
#         "ğŸ“Š Crie grÃ¡ficos para visualizar distribuiÃ§Ãµes",
#         "ğŸ§  Gere conclusÃµes inteligentes sobre os dados"
#     ])
    
#     # Mostrar sugestÃµes em colunas
#     cols = st.columns(min(len(suggestions), 3))
#     for i, suggestion in enumerate(suggestions[:6]):  # MÃ¡ximo 6 sugestÃµes
#         with cols[i % 3]:
#             if st.button(suggestion, key=f"suggestion_{i}", width="stretch"):
#                 # Simular input do usuÃ¡rio
#                 prompt = suggestion.replace("ğŸ“Š", "").replace("ğŸ”—", "").replace("ğŸ¯", "").replace("ğŸ”", "").replace("ğŸ“ˆ", "").replace("ğŸš¨", "").replace("ğŸ“‹", "").replace("ğŸ§ ", "").strip()
#                 st.session_state.messages.append({"role": "user", "content": prompt})
#                 st.rerun()

# =============================================================================
# INPUT E PROCESSAMENTO PRINCIPAL
# =============================================================================

if prompt := st.chat_input("ğŸ’¬ FaÃ§a sua pergunta sobre os dados (EDA completa, grÃ¡ficos, conclusÃµes...)"):
    
    # Incrementar contador
    st.session_state.total_queries += 1
    
    # Adicionar Ã  histÃ³ria de anÃ¡lises
    st.session_state.analysis_history.append({
        "timestamp": datetime.now(),
        "query": prompt,
        "dataset": st.session_state.dataset_name
    })
    
    # Adicionar mensagem do usuÃ¡rio ao histÃ³rico
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Mostrar mensagem do usuÃ¡rio
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Processar resposta do assistente
    with st.chat_message("assistant"):
        
        # Spinner inteligente baseado no tipo de pergunta
        spinner_texts = {
            "grÃ¡fico": "ğŸ¨ Criando visualizaÃ§Ãµes...",
            "plot": "ğŸ“Š Gerando grÃ¡ficos...",
            "visualizaÃ§Ã£o": "ğŸ–¼ï¸ Preparando visualizaÃ§Ãµes...",
            "correlaÃ§Ã£o": "ğŸ”— Analisando correlaÃ§Ãµes...",
            "outlier": "ğŸš¨ Detectando anomalias...",
            "anomalia": "ğŸ” Identificando outliers...",
            "conclusÃ£o": "ğŸ§  Sintetizando insights...",
            "resumo": "ğŸ“ Gerando resumo executivo...",
            "anÃ¡lise completa": "ğŸ”¬ Executando EDA completa...",
            "machine learning": "ğŸ¤– Preparando anÃ¡lise ML...",
            "ml": "âš¡ Executando pipeline ML..."
        }
        
        spinner_text = "ğŸ” Analisando dados..."
        for keyword, text in spinner_texts.items():
            if keyword in prompt.lower():
                spinner_text = text
                break
        
        with st.spinner(spinner_text):

            # 1. Inicialize a variÃ¡vel com um valor seguro fora do try
            response_data = {"output": "Erro desconhecido durante o LangGraph."}
            try:

                try:
                    eda_resultados = analise_eda_completa(df)

                    # Garante que sempre exista "resumo"
                    resumo = eda_resultados.get("resumo", {
                        "n_linhas": df.shape[0],
                        "n_colunas": df.shape[1],
                        "variaveis_numericas": list(df.select_dtypes(include=['float64', 'int64']).columns),
                        "variaveis_categoricas": list(df.select_dtypes(include=['object', 'category']).columns),
                        "qtde_num": len(df.select_dtypes(include=['float64', 'int64']).columns),
                        "qtde_cat": len(df.select_dtypes(include=['object', 'category']).columns),
                        "insights": []
                    })

                    prompt_completo = f"""
                    ğŸ“ Contexto do Dataset

                    - Linhas: {resumo['n_linhas']}
                    - Colunas: {resumo['n_colunas']}
                    - VariÃ¡veis numÃ©ricas ({resumo['qtde_num']}): {resumo['variaveis_numericas']}
                    - VariÃ¡veis categÃ³ricas ({resumo['qtde_cat']}): {resumo['variaveis_categoricas']}
                    - Insights iniciais: {resumo['insights']}

                    â“ Pergunta do usuÃ¡rio:
                    {prompt}
                    """

                    # Executar o grafo LangGraph
                    response_data = graph.invoke(
                        {
                        "input": prompt_completo,
                        "chat_history": st.session_state.messages[-15:],  # MemÃ³ria mais ampla
                        "output": "",
                        "intermediate_results": {}
                        },
                        config={
                            "configurable": {
                                "thread_id": f"eda_session_{st.session_state.session_start.timestamp()}"
                            }
                        }
                    )

                except Exception as e:
                    st.error(f"âš ï¸ Erro ao executar anÃ¡lise EDA: {e}")
                            
                # Extrair resposta final
                final_output = response_data.get("output", "NÃ£o consegui gerar uma anÃ¡lise adequada.")
                

                
                # Limpeza e formataÃ§Ã£o da resposta
                if isinstance(final_output, str):
                    # Remove marcadores de cÃ³digo desnecessÃ¡rios
                    final_output = re.sub(r"^```(?:json|python|text)?\n?", "", final_output)
                    final_output = re.sub(r"\n?```$", "", final_output)
                    final_output = final_output.strip()
                    
                    # FormataÃ§Ã£o especial para JSON estruturado
                    if final_output.startswith(('{', '[')):
                        try:
                            parsed_json = json.loads(final_output)
                            # Se for um resultado estruturado, formatÃ¡-lo melhor
                            if isinstance(parsed_json, dict):
                                formatted_output = ""
                                for key, value in parsed_json.items():
                                    if isinstance(value, dict):
                                        formatted_output += f"\n## {key.replace('_', ' ').title()}\n"
                                        for subkey, subvalue in value.items():
                                            formatted_output += f"**{subkey}:** {subvalue}\n"
                                    else:
                                        formatted_output += f"**{key.replace('_', ' ').title()}:** {value}\n"
                                final_output = formatted_output
                            else:
                                final_output = f"```json\n{json.dumps(parsed_json, ensure_ascii=False, indent=2)}\n```"
                        except json.JSONDecodeError:
                            pass


                # Mostrar resposta formatada
                st.markdown(final_output)
                
                # Verificar e mostrar grÃ¡ficos matplotlib
                if plt.get_fignums():
                    st.pyplot(plt.gcf())
                    plt.clf()
                
                # Adicionar resposta ao histÃ³rico
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": final_output
                })
                
                # Mostrar informaÃ§Ãµes adicionais se a anÃ¡lise foi extensa
                if len(final_output) > 500:
                    st.success("âœ… AnÃ¡lise EDA completa realizada!")
                    
                    # Sugerir prÃ³ximos passos
                    st.info("""
                    ğŸ’¡ **PrÃ³ximos passos sugeridos:**
                    - Explore aspectos especÃ­ficos que chamaram atenÃ§Ã£o
                    - PeÃ§a anÃ¡lises de correlaÃ§Ã£o mais detalhadas  
                    - Solicite grÃ¡ficos especÃ­ficos para variÃ¡veis de interesse
                    - PeÃ§a conclusÃµes e insights acionÃ¡veis
                    """)
                
                # InformaÃ§Ãµes de debug (expansÃ­vel)
                with st.expander("ğŸ” Detalhes da ExecuÃ§Ã£o EDA", expanded=False):
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.subheader("ğŸ“ AnÃ¡lise Solicitada")
                        st.code(prompt, language="text")
                        
                        st.subheader("âš™ï¸ ConfiguraÃ§Ã£o do Sistema")
                        st.json({
                            "dataset": st.session_state.dataset_name,
                            "linhas": df.shape[0],
                            "colunas": df.shape[1],
                            "modelo": Settings.LLM_MODEL,
                            "temperatura": 0,
                            "memÃ³ria_chat": len(st.session_state.messages),
                            "tempo_sessÃ£o": f"{(datetime.now() - st.session_state.session_start).seconds}s"
                        })
                    
                    with col2:
                        st.subheader("ğŸ”„ Resultados IntermediÃ¡rios")
                        intermediate = response_data.get("intermediate_results", {})
                        if intermediate:
                            st.json(intermediate)
                        else:
                            st.info("Processamento direto sem etapas intermediÃ¡rias")
                        
                        st.subheader("ğŸ“Š AnÃ¡lise da Resposta")
                        response_stats = {
                            "tamanho_resposta": len(final_output),
                            "tipo_anÃ¡lise": "Complexa" if len(final_output) > 500 else "Simples",
                            "grÃ¡ficos_gerados": len(plt.get_fignums()) if plt.get_fignums() else 0,
                            "formato": "JSON estruturado" if final_output.startswith(('{', '[')) else "Texto natural"
                        }
                        st.json(response_stats)
                
            except Exception as e:
                # Tratamento robusto de erros
                error_msg = f"âŒ **Erro na anÃ¡lise EDA**\n\n`{str(e)}`"
                st.error("Ops! Algo deu errado durante a anÃ¡lise dos dados.")
                
                # Adicionar erro ao histÃ³rico
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": f"Erro na anÃ¡lise: {str(e)}"
                })
                
                # Debug detalhado do erro
                with st.expander("ğŸ› InformaÃ§Ãµes de Debug"):
                    st.code(f"Tipo do erro: {type(e).__name__}")
                    st.code(f"Mensagem: {str(e)}")
                    st.code("Traceback:")
                    st.code(traceback.format_exc())
                    
                    st.write("**Contexto:**")
                    st.write(f"- Dataset: {st.session_state.dataset_name}")
                    st.write(f"- Shape: {df.shape}")
                    st.write(f"- Consulta: {prompt}")
                
                # SugestÃµes de soluÃ§Ã£o
                st.info("""
                ğŸ’¡ **PossÃ­veis soluÃ§Ãµes:**
                - Tente reformular sua pergunta de forma mais especÃ­fica
                - Verifique se o dataset foi carregado corretamente
                - Para datasets muito grandes, tente anÃ¡lises mais focadas
                - Recarregue a pÃ¡gina se o problema persistir
                """)

# =============================================================================
# CONTROLES E UTILITÃRIOS - APENAS SE HOUVER DATASET
# =============================================================================

if not df.empty:
    st.divider()
    st.subheader("ğŸ› ï¸ Controles do Sistema")

    col1, col2, col3, col4, col5 = st.columns(5)

    with col1:
        if st.button("ğŸ—‘ï¸ Limpar Chat", width="stretch"):
            st.session_state.messages = []
            st.success("Chat limpo!")
            st.rerun()

    with col2:
        if st.button("ğŸ”„ Resetar Sistema", width="stretch"):
            st.cache_resource.clear()
            st.cache_data.clear()
            st.session_state.messages = []
            st.session_state.analysis_history = []
            st.session_state.total_queries = 0
            st.success("Sistema resetado!")
            st.rerun()

    with col3:
        # Exportar anÃ¡lises
        if st.session_state.messages and st.button("ğŸ“¥ Exportar EDA", width="stretch"):
            eda_export = {
                "dataset_info": {
                    "name": st.session_state.dataset_name,
                    "shape": df.shape,
                    "columns": df.columns.tolist(),
                    "dtypes": df.dtypes.astype(str).to_dict()
                },
                "session_info": {
                    "timestamp": datetime.now().isoformat(),
                    "total_queries": st.session_state.total_queries,
                    "duration_seconds": (datetime.now() - st.session_state.session_start).seconds,
                    "analysis_count": len(st.session_state.analysis_history)
                },
                "chat_history": st.session_state.messages,
                "analysis_history": [
                    {
                        "timestamp": h["timestamp"].isoformat(),
                        "query": h["query"],
                        "dataset": h["dataset"]
                    } for h in st.session_state.analysis_history
                ]
            }
            
            st.download_button(
                label="â¬‡ï¸ Download RelatÃ³rio EDA",
                data=json.dumps(eda_export, ensure_ascii=False, indent=2),
                file_name=f"eda_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                width="stretch"
            )

    with col4:
        # SumÃ¡rio do dataset
        if st.button("ğŸ“‹ Info Dataset", width="stretch"):
            st.info(f"""
            **ğŸ“Š {st.session_state.dataset_name}**
            
            **Estrutura:**
            - Linhas: {df.shape[0]:,}
            - Colunas: {df.shape[1]}
            - MemÃ³ria: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB
            
            **Tipos:**
            - NumÃ©ricas: {len(df.select_dtypes(include=['number']).columns)}
            - CategÃ³ricas: {len(df.select_dtypes(include=['object']).columns)}
            
            **Qualidade:**
            - Nulos: {df.isnull().sum().sum():,}
            - Duplicatas: {df.duplicated().sum():,}
            """)

    with col5:
        # HistÃ³rico de anÃ¡lises
        if st.session_state.analysis_history and st.button("ğŸ“ˆ HistÃ³rico", width="stretch"):
            st.write("**ğŸ•’ HistÃ³rico de AnÃ¡lises:**")
            for i, analysis in enumerate(st.session_state.analysis_history[-5:], 1):
                st.write(f"{i}. *{analysis['timestamp'].strftime('%H:%M')}* - {analysis['query'][:50]}...")

# =============================================================================
# GUIA DE USO PARA EDA - APENAS SE HOUVER DATASET
# =============================================================================

if not df.empty:
    with st.expander("ğŸ“– Guia Completo de EDA - Atendendo aos Requisitos da Banca", expanded=False):
        
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "ğŸ“‹ DescriÃ§Ã£o dos Dados",
            "ğŸ“ˆ PadrÃµes e TendÃªncias", 
            "ğŸš¨ DetecÃ§Ã£o de Outliers",
            "ğŸ”— RelaÃ§Ãµes entre VariÃ¡veis",
            "ğŸ§  ConclusÃµes Inteligentes"
        ])
        
        with tab1:
            st.markdown("""
            ## ğŸ“Š DescriÃ§Ã£o dos Dados
            
            **Perguntas que vocÃª pode fazer:**
            
            ### Tipos de Dados:
            - "Quais sÃ£o os tipos de dados (numÃ©ricos, categÃ³ricos)?"
            - "Mostre a estrutura do dataset"
            - "Descreva as caracterÃ­sticas de cada coluna"
            
            ### DistribuiÃ§Ãµes:
            - "Qual a distribuiÃ§Ã£o de cada variÃ¡vel?"
            - "Crie histogramas das variÃ¡veis numÃ©ricas"
            - "Mostre a distribuiÃ§Ã£o da variÃ¡vel [nome]"
            
            ### Intervalos e EstatÃ­sticas:
            - "Qual o intervalo de cada variÃ¡vel (mÃ­nimo, mÃ¡ximo)?"
            - "Quais sÃ£o as medidas de tendÃªncia central?"
            - "Calcule mÃ©dia, mediana para todas as variÃ¡veis"
            - "Qual a variabilidade dos dados (desvio padrÃ£o, variÃ¢ncia)?"
            """)
        
        with tab2:
            st.markdown("""
            ## ğŸ“ˆ IdentificaÃ§Ã£o de PadrÃµes e TendÃªncias
            
            **AnÃ¡lises temporais:**
            - "Existem padrÃµes temporais nos dados?"
            - "Analise a evoluÃ§Ã£o temporal da variÃ¡vel Time"
            - "Mostre tendÃªncias ao longo do tempo"
            
            **FrequÃªncias:**
            - "Quais os valores mais frequentes?"
            - "Identifique valores menos frequentes"
            - "Analise a distribuiÃ§Ã£o de frequÃªncias"
            
            **Agrupamentos:**
            - "Existem agrupamentos (clusters) nos dados?"
            - "Identifique padrÃµes de agrupamento"
            - "Analise segmentaÃ§Ã£o natural dos dados"
            """)
        
        with tab3:
            st.markdown("""
            ## ğŸš¨ DetecÃ§Ã£o de Anomalias (Outliers)
            
            **IdentificaÃ§Ã£o:**
            - "Existem valores atÃ­picos nos dados?"
            - "Detecte outliers em todas as variÃ¡veis"
            - "Mostre boxplots para identificar anomalias"
            
            **AnÃ¡lise de Impacto:**
            - "Como esses outliers afetam a anÃ¡lise?"
            - "Qual o impacto dos outliers nas estatÃ­sticas?"
            
            **Tratamento:**
            - "Os outliers podem ser removidos?"
            - "Sugira tratamento para valores atÃ­picos"
            - "Analise se outliers devem ser investigados"
            """)
        
        with tab4:
            st.markdown("""
            ## ğŸ”— RelaÃ§Ãµes entre VariÃ¡veis
            
            **CorrelaÃ§Ãµes:**
            - "Como as variÃ¡veis estÃ£o relacionadas?"
            - "Existe correlaÃ§Ã£o entre as variÃ¡veis?"
            - "Crie matriz de correlaÃ§Ã£o"
            - "Mostre heatmap de correlaÃ§Ãµes"
            
            **VisualizaÃ§Ãµes:**
            - "Crie grÃ¡ficos de dispersÃ£o entre variÃ¡veis"
            - "Mostre relaÃ§Ãµes atravÃ©s de scatter plots"
            - "Analise tabelas cruzadas"
            
            **InfluÃªncias:**
            - "Quais variÃ¡veis tÃªm maior influÃªncia?"
            - "Identifique variÃ¡veis mais importantes"
            - "Analise relaÃ§Ã£o com a variÃ¡vel target"
            """)
        
        with tab5:
            st.markdown("""
            ## ğŸ§  ConclusÃµes Inteligentes
            
            **SÃ­ntese Completa:**
            - "Quais conclusÃµes vocÃª obteve dos dados?"
            - "Resuma os principais insights"
            - "Gere relatÃ³rio executivo"
            
            **Insights AcionÃ¡veis:**
            - "Que aÃ§Ãµes vocÃª recomenda baseado na anÃ¡lise?"
            - "Quais sÃ£o os prÃ³ximos passos?"
            - "Identifique oportunidades nos dados"
            
            **AnÃ¡lise Preditiva:**
            - "Execute anÃ¡lise completa de machine learning"
            - "Quais modelos sÃ£o mais adequados?"
            - "Avalie potencial preditivo dos dados"
            """)

# =============================================================================
# EXEMPLOS ESPECÃFICOS PARA DATASETS - APENAS SE HOUVER DADOS
# =============================================================================

if not df.empty:
    
    if "credit" in st.session_state.dataset_name.lower() or "fraud" in st.session_state.dataset_name.lower():
        st.info("""
        ğŸ’³ **Exemplos especÃ­ficos para Credit Card Fraud:**
        
        - "Analise a distribuiÃ§Ã£o de fraudes vs transaÃ§Ãµes normais"
        - "Qual a relaÃ§Ã£o entre Amount e Class?"
        - "Existem padrÃµes temporais nas fraudes?"
        - "Como as variÃ¡veis V1-V28 (PCA) se relacionam com fraudes?"
        - "Detecte outliers que podem indicar fraudes"
        - "Crie modelos de machine learning para detectar fraudes"
        """)
    else:
        st.info(f"""
        ğŸ” **Exemplos especÃ­ficos para seu dataset ({st.session_state.dataset_name}):**
        
        - "FaÃ§a uma anÃ¡lise exploratÃ³ria completa"
        - "Identifique padrÃµes e tendÃªncias nos dados"
        - "Detecte outliers e anomalias"
        - "Analise correlaÃ§Ãµes entre variÃ¡veis"
        - "Gere insights e conclusÃµes"
        """)

# =============================================================================
# INSTRUÃ‡Ã•ES INICIAIS - APENAS SE NÃƒO HOUVER DATASET
# =============================================================================

if df.empty:
    st.divider()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“š Como Funciona")
        st.markdown("""
        **1. Carregue seus dados** ğŸ“
        - FaÃ§a upload de qualquer arquivo CSV
        - Ou use nosso dataset de exemplo (Credit Card Fraud)
        
        **2. FaÃ§a perguntas naturais** ğŸ’¬
        - "Quais sÃ£o os tipos de dados?"
        - "Mostre a distribuiÃ§Ã£o das variÃ¡veis"
        - "Existem outliers nos dados?"
        
        **3. Receba anÃ¡lises inteligentes** ğŸ§ 
        - GrÃ¡ficos automÃ¡ticos
        - Insights acionÃ¡veis
        - ConclusÃµes detalhadas
        """)
    
    with col2:
        st.subheader("ğŸ¯ Principais Recursos")
        st.markdown("""
        **AnÃ¡lise AutomÃ¡tica** ğŸ”
        - DetecÃ§Ã£o de tipos de dados
        - EstatÃ­sticas descritivas
        - IdentificaÃ§Ã£o de padrÃµes
        
        **VisualizaÃ§Ãµes** ğŸ“Š
        - Histogramas e boxplots
        - CorrelaÃ§Ãµes e heatmaps
        - GrÃ¡ficos personalizados
        
        **Insights AvanÃ§ados** ğŸš€
        - DetecÃ§Ã£o de outliers
        - Machine Learning
        - RecomendaÃ§Ãµes prÃ¡ticas
        """)


# =============================================================================
# RODAPÃ‰
# =============================================================================

st.divider()
st.markdown(
    """
    <div style='text-align: center; color: #666; font-size: 0.8em;'>
        ğŸ“ <strong>Sistema EDA GenÃ©rico - Atividade Banca Examinadora</strong><br>
        âœ… Suporte completo a qualquer CSV â€¢ ğŸ“Š EDA Automatizada â€¢ ğŸ¤– IA Integrada â€¢ ğŸ§  ConclusÃµes Inteligentes<br>
        ğŸ”¬ Atende todos os requisitos: DescriÃ§Ã£o â€¢ PadrÃµes â€¢ Outliers â€¢ CorrelaÃ§Ãµes â€¢ Insights
    </div>
    """, 
    unsafe_allow_html=True
)


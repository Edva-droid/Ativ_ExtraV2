import json
import re
import streamlit as st
import pandas as pd
from src.agent.agent_orquestrador import criar_orquestrador
from src.agent.config_agent import Settings
from src.data.bases import download_base
from src.agent.eda_utils import analise_eda_completa
from src.util.utils import gerar_hash_df_leve
from langchain_groq import ChatGroq
import matplotlib.pyplot as plt
import traceback
from datetime import datetime
import io
import zipfile

# =============================================================================
# CONFIGURA√á√ÉO INICIAL
# =============================================================================

st.set_page_config(
    page_title="ü§ñ EDA Inteligente - An√°lise de CSV com IA", 
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://github.com/seu-usuario/seu-repo',
        'Report a bug': "https://github.com/seu-usuario/seu-repo/issues",
        'About': "Sistema EDA usando LangGraph e IA - Trabalha com qualquer CSV"
    }
)

# =============================================================================
# FUN√á√ïES DE CARREGAMENTO DE DADOS
# =============================================================================

def clean_dataframe_for_streamlit(df):
    """
    Limpa o DataFrame para compatibilidade com Streamlit/PyArrow
    """
    df_clean = df.copy()
    
    try:
        # Converter tipos problem√°ticos
        for col in df_clean.columns:
            # Verificar se √© uma coluna problem√°tica
            if df_clean[col].dtype == 'object':
                # Tentar converter para num√©rico se poss√≠vel
                try:
                    # Se todos os valores n√£o-nulos s√£o n√∫meros, converter
                    pd.to_numeric(df_clean[col], errors='raise')
                    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')
                except:
                    # Se n√£o conseguir converter, manter como string
                    df_clean[col] = df_clean[col].astype(str)
            
            # Lidar com tipos Int64 problem√°ticos
            elif str(df_clean[col].dtype) in ['Int64', 'int64']:
                # Converter para int32 ou float se houver NaNs
                if df_clean[col].isna().any():
                    df_clean[col] = df_clean[col].astype('float64')
                else:
                    try:
                        df_clean[col] = df_clean[col].astype('int32')
                    except:
                        df_clean[col] = df_clean[col].astype('float64')
            
            # Converter boolean nullable para bool padr√£o
            elif str(df_clean[col].dtype) == 'boolean':
                df_clean[col] = df_clean[col].astype('bool')
        
        return df_clean
    
    except Exception as e:
        # Se a limpeza falhar, converter tudo para string como √∫ltimo recurso
        print(f"Erro na limpeza, convertendo para strings: {e}")
        for col in df_clean.columns:
            df_clean[col] = df_clean[col].astype(str)
        return df_clean


def load_csv_file(uploaded_file):
    """Carrega arquivo CSV uploaded"""
    try:
        # Reset do ponteiro do arquivo
        uploaded_file.seek(0)
        
        # Verificar se √© um arquivo zip
        if uploaded_file.name.endswith('.zip'):
            with zipfile.ZipFile(uploaded_file, 'r') as zip_ref:
                # Listar arquivos no zip
                file_list = zip_ref.namelist()
                csv_files = [f for f in file_list if f.endswith('.csv')]
                
                if not csv_files:
                    st.error("‚ùå Nenhum arquivo CSV encontrado no ZIP")
                    return None
                
                # Se houver m√∫ltiplos CSVs, deixar o usu√°rio escolher
                if len(csv_files) > 1:
                    selected_file = st.selectbox(
                        "üìÅ M√∫ltiplos CSVs encontrados. Selecione um:",
                        csv_files
                    )
                else:
                    selected_file = csv_files[0]
                
                # Ler o CSV selecionado
                with zip_ref.open(selected_file) as csv_file:
                    df = pd.read_csv(csv_file)
                    
        else:
            # Arquivo CSV direto - tentar diferentes configura√ß√µes
            encodings_to_try = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']
            df = None
            
            for encoding in encodings_to_try:
                try:
                    # Reset do ponteiro antes de cada tentativa
                    uploaded_file.seek(0)
                    
                    # Primeiro, tentar ler normalmente
                    try:
                        df = pd.read_csv(uploaded_file, encoding=encoding)
                        break
                    except:
                        # Se falhar, tentar sem header (caso a primeira linha seja dados)
                        uploaded_file.seek(0)
                        df = pd.read_csv(uploaded_file, encoding=encoding, header=None)
                        
                        # Gerar nomes de colunas se n√£o houver header
                        df.columns = [f'Column_{i+1}' for i in range(len(df.columns))]
                        st.info(f"üìã Arquivo carregado sem cabe√ßalhos. Colunas nomeadas como: {', '.join(df.columns)}")
                        break
                        
                except UnicodeDecodeError:
                    continue
                except Exception as e:
                    # Log do erro mas continue tentando
                    st.warning(f"Tentativa com encoding {encoding} falhou: {str(e)}")
                    continue
            
            if df is None:
                st.error("‚ùå N√£o foi poss√≠vel ler o arquivo CSV com nenhum encoding testado.")
                return None
        
        # Validar se o DataFrame foi carregado corretamente
        if df is None or df.empty:
            st.error("‚ùå DataFrame carregado est√° vazio")
            return None
        
        # Verificar se as colunas t√™m nomes estranhos (apenas n√∫meros)
        if all(str(col).isdigit() or col == 0 for col in df.columns):
            st.warning("‚ö†Ô∏è Detectadas colunas com nomes num√©ricos. Possivelmente o arquivo n√£o tem cabe√ßalhos apropriados.")
            # Renomear colunas para algo mais leg√≠vel
            df.columns = [f'Feature_{i+1}' for i in range(len(df.columns))]
            st.info(f"üîÑ Colunas renomeadas para: {', '.join(df.columns)}")
        
        # NOVO: Limpar DataFrame para compatibilidade com Streamlit
        df_clean = clean_dataframe_for_streamlit(df)
        
        st.session_state["intermediate_results"] = {}
        # st.session_state["intermediate_results"]["analise_eda"] = eda_resultados
        # Log de sucesso com informa√ß√µes b√°sicas
        st.success(f"üìä Dataset carregado com sucesso: {df_clean.shape[0]} linhas x {df_clean.shape[1]} colunas")
        
        return df_clean
        
    except Exception as e:
        st.error(f"‚ùå Erro cr√≠tico ao carregar arquivo: {str(e)}")
        st.error("üí° Verifique se o arquivo √© um CSV v√°lido")
        
        # Debug adicional
        st.error("üîç Informa√ß√µes de debug:")
        st.code(f"Erro: {type(e).__name__}: {str(e)}")
        return None

@st.cache_data
def get_default_dataframe():
    try:
        df = download_base()
        
        return df
    except Exception as e:
        st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel carregar dataset padr√£o: {e}")
        return pd.DataFrame()

@st.cache_resource
def get_llm():
    """Inicializa o LLM uma √∫nica vez com configura√ß√µes otimizadas"""
    try:
        return ChatGroq(
            temperature=0,
            # groq_api_key=Settings.GROQ_API_KEY,
            model=Settings.LLM_MODEL,
            max_tokens=4096,
            timeout=60  # Timeout maior para an√°lises complexas
        )
    except Exception as e:
        st.error(f"‚ùå Erro ao inicializar LLM: {e}")
        return None

@st.cache_resource
def get_orchestrator(_llm, _df_hash):
    """Cria o orquestrador com base no hash do DataFrame"""
    if _llm is None or _df_hash is None:
        return None
    try:
        # Usar o hash para garantir que o cache seja invalidado quando o DF mudar
        return criar_orquestrador(_llm, st.session_state.current_df)
    except Exception as e:
        st.error(f"‚ùå Erro ao criar orquestrador: {e}")
        return None

# =============================================================================
# INICIALIZA√á√ÉO DE ESTADO
# =============================================================================

# Inicializar LLM
llm = get_llm()

# Inicializar estado da sess√£o - COME√áAR VAZIO
if "messages" not in st.session_state:
    st.session_state.messages = []

if "total_queries" not in st.session_state:
    st.session_state.total_queries = 0

if "session_start" not in st.session_state:
    st.session_state.session_start = datetime.now()

# MODIFICA√á√ÉO: Inicializar com DataFrame vazio
if "current_df" not in st.session_state:
    st.session_state.current_df = pd.DataFrame()  # Come√ßa vazio

if "dataset_name" not in st.session_state:
    st.session_state.dataset_name = None  # Come√ßa sem dataset

if "analysis_history" not in st.session_state:
    st.session_state.analysis_history = []

# =============================================================================
# INTERFACE PRINCIPAL
# =============================================================================

st.title("ü§ñ EDA Inteligente - An√°lise de CSV com IA")
st.markdown("*Sistema gen√©rico para an√°lise explorat√≥ria de qualquer arquivo CSV*")

# =============================================================================
# SE√á√ÉO DE CARREGAMENTO DE DADOS
# =============================================================================

st.header("üìÅ Carregamento de Dados")

# Exibir instru√ß√µes se n√£o houver dataset carregado
if st.session_state.current_df.empty:
    st.info("üëã **Bem-vindo ao Sistema EDA Inteligente!**\n\nPara come√ßar, carregue um arquivo CSV ou use o dataset padr√£o abaixo.")

col1, col2 = st.columns([3, 1])

with col1:
    uploaded_file = st.file_uploader(
        "üîÑ Carregue seu arquivo CSV",
        type=['csv'],
        help="Suporta arquivos CSV. O sistema analisar√° qualquer estrutura de dados."
    )

with col2:
    use_default = st.button("üìä Usar Dataset Padr√£o", width="stretch")

# Processar carregamento de arquivo
if uploaded_file is not None:
    # Mostrar informa√ß√µes do arquivo antes do processamento
    st.write("**Informa√ß√µes do arquivo:**")
    st.write(f"- Nome: {uploaded_file.name}")
    st.write(f"- Tamanho: {uploaded_file.size:,} bytes ({uploaded_file.size/1024:.1f} KB)")
    st.write(f"- Tipo: {uploaded_file.type}")
    
    # Verificar se o arquivo n√£o √© muito grande (limite de 50MB)
    if uploaded_file.size > 50 * 1024 * 1024:
        st.warning("‚ö†Ô∏è Arquivo muito grande (>50MB). O carregamento pode ser lento.")
    
    # Usar progress bar
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        status_text.text("üîç Iniciando carregamento...")
        progress_bar.progress(10)
        
        status_text.text("üìà Processando arquivo CSV...")
        progress_bar.progress(30)
        
        new_df = load_csv_file(uploaded_file)
        progress_bar.progress(70)
        
        if new_df is not None:
            status_text.text("‚úÖ Validando dados...")
            progress_bar.progress(90)
            
            # Debug: verificar se o DataFrame foi carregado
            st.write(f"**DataFrame processado:** {new_df.shape[0]} linhas x {new_df.shape[1]} colunas")
            st.write(f"**Colunas encontradas:** {new_df.columns.tolist()}")
            
            # Atualizar estado da sess√£o
            st.session_state.current_df = new_df
            st.session_state.dataset_name = uploaded_file.name
            st.session_state.messages = []  # Limpar hist√≥rico ao carregar novo dataset
            st.session_state.analysis_history = []
            
            progress_bar.progress(100)
            status_text.text("‚úÖ Carregamento conclu√≠do!")
            
            st.success(f"Arquivo '{uploaded_file.name}' carregado com sucesso!")
            
            # Mostrar preview dos dados
            with st.expander("üëÄ Preview dos dados carregados", expanded=True):
                try:
                    # Mostrar apenas informa√ß√µes b√°sicas se houver problemas de exibi√ß√£o
                    st.write(f"**Shape:** {new_df.shape[0]} linhas √ó {new_df.shape[1]} colunas")
                    st.write(f"**Colunas:** {', '.join(new_df.columns.tolist()[:10])}{'...' if len(new_df.columns) > 10 else ''}")
                    
                    # Tentar mostrar o dataframe, com fallback para informa√ß√µes b√°sicas
                    try:
                        st.dataframe(new_df.head(), width="stretch")
                    except Exception as display_error:
                        st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel exibir o preview visual: {display_error}")
                        st.write("**Primeiras 5 linhas (formato texto):**")
                        st.text(str(new_df.head()))
                    
                    # Informa√ß√µes dos tipos de dados
                    st.write("**Tipos de dados:**")
                    for col, dtype in new_df.dtypes.items():
                        st.write(f"- **{col}**: {str(dtype)}")
                        
                except Exception as preview_error:
                    st.error(f"Erro no preview: {preview_error}")
                    st.write("Arquivo carregado, mas preview n√£o dispon√≠vel.")
            
            # # For√ßar atualiza√ß√£o da interface
            # import time
            # time.sleep(0.5)  # Pequena pausa para garantir que tudo foi processado
            # st.rerun()
            
        else:
            progress_bar.progress(100)
            status_text.text("‚ùå Falha no carregamento")
            st.error("‚ùå N√£o foi poss√≠vel carregar o arquivo")
            st.info("üí° Tente verificar se o arquivo est√° no formato CSV correto")
    
    except Exception as e:
        progress_bar.progress(100)
        status_text.text("‚ùå Erro no processamento")
        st.error(f"Erro inesperado: {str(e)}")
        st.code(f"Erro t√©cnico: {type(e).__name__}: {str(e)}")
    
    finally:
        # Limpar progress bar ap√≥s 2 segundos
        import time
        time.sleep(2)
        progress_bar.empty()
        status_text.empty()

# Usar dataset padr√£o
if use_default:
    default_df = get_default_dataframe()
    if not default_df.empty:
        st.session_state.current_df = default_df
        st.session_state.dataset_name = "Dataset Padr√£o (Credit Card Fraud)"
        st.session_state.messages = []
        st.session_state.analysis_history = []
        st.success("‚úÖ Dataset padr√£o carregado!")
        st.rerun()

# Obter DataFrame atual
df = st.session_state.current_df
# 99999999
if "current_df" in st.session_state:
    df = st.session_state.current_df

    if df is not None and not df.empty and len(df.columns) > 0:
        current_hash = gerar_hash_df_leve(df)

        if ("eda_summary" not in st.session_state) or (st.session_state.get("eda_hash") != current_hash):
            st.session_state.eda_summary = analise_eda_completa(df)
            st.session_state.eda_hash = current_hash
            st.success("‚úÖ Resumo EDA gerado/atualizado!")

        # st.write(st.session_state.eda_summary)
    else:
        st.warning("‚ö†Ô∏è DataFrame est√° vazio ou n√£o possui colunas.")
else:
    st.warning("üìÇ Nenhum DataFrame carregado ainda.")


# =============================================================================
# VALIDA√á√ÉO E CRIA√á√ÉO DO ORQUESTRADOR
# =============================================================================

# Criar hash do DataFrame para cache - apenas se n√£o estiver vazio
df_hash = None
if not df.empty:
    df_hash = hash(str(df.shape) + str(df.columns.tolist()) + str(df.iloc[0].tolist() if len(df) > 0 else []))

graph = get_orchestrator(llm, df_hash) if llm is not None and not df.empty else None

# =============================================================================
# SIDEBAR - MOSTRAR APENAS SE HOUVER DATASET
# =============================================================================

with st.sidebar:
    if not df.empty and st.session_state.dataset_name:
        st.header("üìä Informa√ß√µes do Dataset")
        st.write(f"**Dataset Atual:** {st.session_state.dataset_name}")
        
        # Informa√ß√µes b√°sicas
        col1, col2 = st.columns(2)
        with col1:
            st.metric("üìè Linhas", f"{df.shape[0]:.0f}")
        with col2:
            st.metric("üìã Colunas", df.shape[1])
        
        # Tipos de dados detalhados
        st.subheader("üè∑Ô∏è An√°lise de Tipos")
        numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
        datetime_cols = df.select_dtypes(include=['datetime']).columns.tolist()
        
        if numeric_cols:
            st.write(f"üî¢ **Num√©ricas ({len(numeric_cols)}):**")
            for col in numeric_cols[:5]:  # Mostrar apenas 5
                st.write(f"  ‚Ä¢ {col}")
            if len(numeric_cols) > 5:
                st.write(f"  ... e mais {len(numeric_cols) - 5}")
        
        if categorical_cols:
            st.write(f"üìù **Categ√≥ricas ({len(categorical_cols)}):**")
            for col in categorical_cols[:5]:
                st.write(f"  ‚Ä¢ {col}")
            if len(categorical_cols) > 5:
                st.write(f"  ... e mais {len(categorical_cols) - 5}")
        
        if datetime_cols:
            st.write(f"üìÖ **Data/Hora ({len(datetime_cols)}):**")
            for col in datetime_cols:
                st.write(f"  ‚Ä¢ {col}")
        
        # An√°lise de qualidade
        st.subheader("üîç Qualidade dos Dados")
        null_counts = df.isnull().sum().sum()
        duplicate_counts = df.duplicated().sum()
        
        # M√©tricas de Varia√ß√£o/Unicidade
        constant_cols_count = (df.nunique() == 1).sum()
        avg_cardinality = df.nunique().mean()
            
        if null_counts > 0:
            st.warning(f"‚ö†Ô∏è {null_counts:,} valores nulos ({(null_counts/df.size*100):.1f}%)")
        else:
            st.success("‚úÖ Sem valores nulos")
        
        if duplicate_counts > 0:
            st.warning(f"üîÑ {duplicate_counts:,} linhas duplicadas")
        else:
            st.success("‚úÖ Sem duplicadas")

        if constant_cols_count > 0:
            st.warning(f"‚ö†Ô∏è {constant_cols_count:,} colunas sem varia√ß√£o")
        else:
            st.success("‚úÖ Todas as colunas t√™m varia√ß√£o")
        
        st.info(f"üìà Cardinalidade m√©dia: {avg_cardinality:.1f}")

        # Uso de mem√≥ria
        memory_usage = df.memory_usage(deep=True).sum() / 1024**2
        if memory_usage > 100:
            st.error(f"üíæ {memory_usage:.1f} MB (Alto)")
        elif memory_usage > 10:
            st.warning(f"üíæ {memory_usage:.1f} MB (M√©dio)")
        else:
            st.success(f"üíæ {memory_usage:.1f} MB (Baixo)")
        
        # Estat√≠sticas da sess√£o
        st.divider()
        st.subheader("üìà Estat√≠sticas da Sess√£o")
        st.write(f"üî¢ Consultas realizadas: {st.session_state.total_queries}")
        st.write(f"üìã An√°lises no hist√≥rico: {len(st.session_state.analysis_history)}")
        
        duration = datetime.now() - st.session_state.session_start
        minutes = duration.seconds // 60
        seconds = duration.seconds % 60
        st.write(f"‚è±Ô∏è Tempo de sess√£o: {minutes}min {seconds}s")
        
    else:
        # Estado inicial - sem dataset
        st.header("üöÄ Comece Aqui!")
        st.write("**Para usar o sistema:**")
        st.write("1. üì§ Carregue um arquivo CSV")
        st.write("2. üìä Ou use o dataset padr√£o")
        st.write("3. üí¨ Fa√ßa perguntas sobre os dados")
        
        st.divider()
        st.subheader("üéØ O que voc√™ pode fazer:")
        st.write("‚Ä¢ An√°lise explorat√≥ria automatizada")
        st.write("‚Ä¢ Detec√ß√£o de outliers e anomalias") 
        st.write("‚Ä¢ Correla√ß√µes e rela√ß√µes")
        st.write("‚Ä¢ Visualiza√ß√µes inteligentes")
        st.write("‚Ä¢ Insights e conclus√µes")
        st.write("‚Ä¢ Machine Learning")
    
    # Status do sistema - sempre mostrar
    st.divider()
    st.subheader("üîß Status do Sistema")
    
    status_llm = "‚úÖ" if llm else "‚ùå"
    status_data = "‚úÖ" if not df.empty else "‚è≥"
    status_graph = "‚úÖ" if graph else "‚è≥"
    
    st.write(f"{status_llm} LLM (Groq)")
    st.write(f"{status_data} Dataset")
    st.write(f"{status_graph} Orquestrador")

# =============================================================================
# VALIDA√á√ÉO DO SISTEMA - MOSTRAR APENAS SE TENTATIVA DE USO SEM DATASET
# =============================================================================

# Verificar se o sistema est√° pronto para an√°lises
system_ready = all([llm, not df.empty, graph])

# Se n√£o h√° dataset carregado, mostrar instru√ß√£o amig√°vel
if df.empty:
    st.warning("üìã **Aguardando carregamento de dados**")
    st.info("Carregue um arquivo CSV ou use o dataset padr√£o para come√ßar a an√°lise.")
    
    # Mostrar preview do que est√° dispon√≠vel
    with st.expander("üîç Preview das Funcionalidades Dispon√≠veis"):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            **üìä An√°lise Descritiva**
            - Tipos de dados
            - Estat√≠sticas descritivas
            - Distribui√ß√µes
            - Valores √∫nicos
            """)
        
        with col2:
            st.markdown("""
            **üìà Visualiza√ß√µes**
            - Histogramas
            - Boxplots
            - Correla√ß√µes
            - Scatter plots
            """)
        
        with col3:
            st.markdown("""
            **üß† Insights**
            - Detec√ß√£o de outliers
            - Padr√µes temporais
            - Conclus√µes autom√°ticas
            - Recomenda√ß√µes
            """)
    
    st.stop()  # Parar aqui se n√£o h√° dataset

# Se h√° problemas no sistema com dataset carregado
if not system_ready and not df.empty:
    st.error("‚ùå Sistema n√£o est√° pronto para uso")
    
    if llm is None:
        st.error("üîß **LLM n√£o inicializado** - Verifique a chave API do Groq")
    
    if graph is None:
        st.error("üîÄ **Orquestrador n√£o criado** - Verifique as depend√™ncias")
    
    st.info("üí° Corrija os problemas acima para continuar")
    st.stop()

# =============================================================================
# √ÅREA DO CHAT INTELIGENTE - APENAS SE DATASET CARREGADO
# =============================================================================

st.header("üí¨ Chat Inteligente para EDA")

# Container para as mensagens do chat
chat_container = st.container()

with chat_container:
    # Exibir hist√≥rico de mensagens
    for i, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # Mostrar timestamp para an√°lises importantes
            if message["role"] == "assistant" and len(message["content"]) > 200:
                st.caption(f"üïí An√°lise #{i//2 + 1}")

# =============================================================================
# SUGEST√ïES INTELIGENTES BASEADAS NOS DADOS
# =============================================================================

# if not st.session_state.messages and not df.empty:  # Apenas se n√£o houver hist√≥rico e houver dataset
#     st.info("üí° **Sugest√µes baseadas no seu dataset:**")
    
#     suggestions = []
    
#     # Sugest√µes baseadas na estrutura dos dados
#     # Para datasets com muitas colunas num√©ricas
#     numeric_cols = df.select_dtypes(include=['number']).columns
#     if len(numeric_cols) > 5:
#         suggestions.append("üìä Fa√ßa uma an√°lise descritiva completa dos dados")
#         suggestions.append("üîó Analise a correla√ß√£o entre as vari√°veis num√©ricas")
    
#     # Para datasets com vari√°vel target aparente
#     if any('class' in col.lower() for col in df.columns):
#         suggestions.append("üéØ Analise a distribui√ß√£o da vari√°vel target (class)")
#         suggestions.append("üîç Identifique padr√µes relacionados √† classifica√ß√£o")
    
#     # Para datasets temporais
#     if any('time' in col.lower() or 'date' in col.lower() for col in df.columns):
#         suggestions.append("üìà Analise padr√µes temporais nos dados")
    
#     # Para detec√ß√£o de anomalias
#     if len(df) > 1000:
#         suggestions.append("üö® Detecte outliers e anomalias nos dados")
    
#     # Sugest√µes gerais
#     suggestions.extend([
#         "üìã Descreva os tipos de dados e estrutura do dataset",
#         "üìä Crie gr√°ficos para visualizar distribui√ß√µes",
#         "üß† Gere conclus√µes inteligentes sobre os dados"
#     ])
    
#     # Mostrar sugest√µes em colunas
#     cols = st.columns(min(len(suggestions), 3))
#     for i, suggestion in enumerate(suggestions[:6]):  # M√°ximo 6 sugest√µes
#         with cols[i % 3]:
#             if st.button(suggestion, key=f"suggestion_{i}", width="stretch"):
#                 # Simular input do usu√°rio
#                 prompt = suggestion.replace("üìä", "").replace("üîó", "").replace("üéØ", "").replace("üîç", "").replace("üìà", "").replace("üö®", "").replace("üìã", "").replace("üß†", "").strip()
#                 st.session_state.messages.append({"role": "user", "content": prompt})
#                 st.rerun()

# =============================================================================
# INPUT E PROCESSAMENTO PRINCIPAL
# =============================================================================

if prompt := st.chat_input("üí¨ Fa√ßa sua pergunta sobre os dados (EDA completa, gr√°ficos, conclus√µes...)"):
    
    # Incrementar contador
    st.session_state.total_queries += 1
    
    # Adicionar √† hist√≥ria de an√°lises
    st.session_state.analysis_history.append({
        "timestamp": datetime.now(),
        "query": prompt,
        "dataset": st.session_state.dataset_name
    })
    
    # Adicionar mensagem do usu√°rio ao hist√≥rico
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Mostrar mensagem do usu√°rio
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Processar resposta do assistente
    with st.chat_message("assistant"):
        
        # Spinner inteligente baseado no tipo de pergunta
        spinner_texts = {
            "gr√°fico": "üé® Criando visualiza√ß√µes...",
            "plot": "üìä Gerando gr√°ficos...",
            "visualiza√ß√£o": "üñºÔ∏è Preparando visualiza√ß√µes...",
            "correla√ß√£o": "üîó Analisando correla√ß√µes...",
            "outlier": "üö® Detectando anomalias...",
            "anomalia": "üîç Identificando outliers...",
            "conclus√£o": "üß† Sintetizando insights...",
            "resumo": "üìù Gerando resumo executivo...",
            "an√°lise completa": "üî¨ Executando EDA completa...",
            "machine learning": "ü§ñ Preparando an√°lise ML...",
            "ml": "‚ö° Executando pipeline ML..."
        }
        
        spinner_text = "üîç Analisando dados..."
        for keyword, text in spinner_texts.items():
            if keyword in prompt.lower():
                spinner_text = text
                break
        
        with st.spinner(spinner_text):

            # 1. Inicialize a vari√°vel com um valor seguro fora do try
            response_data = {"output": "Erro desconhecido durante o LangGraph."}
            try:

                try:
                    eda_resultados = analise_eda_completa(df)

                    # Garante que sempre exista "resumo"
                    resumo = eda_resultados.get("resumo", {
                        "n_linhas": df.shape[0],
                        "n_colunas": df.shape[1],
                        "variaveis_numericas": list(df.select_dtypes(include=['float64', 'int64']).columns),
                        "variaveis_categoricas": list(df.select_dtypes(include=['object', 'category']).columns),
                        "qtde_num": len(df.select_dtypes(include=['float64', 'int64']).columns),
                        "qtde_cat": len(df.select_dtypes(include=['object', 'category']).columns),
                        "insights": []
                    })

                    prompt_completo = f"""
                    üìù Contexto do Dataset

                    - Linhas: {resumo['n_linhas']}
                    - Colunas: {resumo['n_colunas']}
                    - Vari√°veis num√©ricas ({resumo['qtde_num']}): {resumo['variaveis_numericas']}
                    - Vari√°veis categ√≥ricas ({resumo['qtde_cat']}): {resumo['variaveis_categoricas']}
                    - Insights iniciais: {resumo['insights']}

                    ‚ùì Pergunta do usu√°rio:
                    {prompt}
                    """

                    # Executar o grafo LangGraph
                    response_data = graph.invoke(
                        {
                        "input": prompt_completo,
                        "chat_history": st.session_state.messages[-15:],  # Mem√≥ria mais ampla
                        "output": "",
                        "intermediate_results": {}
                        },
                        config={
                            "configurable": {
                                "thread_id": f"eda_session_{st.session_state.session_start.timestamp()}"
                            }
                        }
                    )

                except Exception as e:
                    st.error(f"‚ö†Ô∏è Erro ao executar an√°lise EDA: {e}")
                            
                # Extrair resposta final
                final_output = response_data.get("output", "N√£o consegui gerar uma an√°lise adequada.")
                

                
                # Limpeza e formata√ß√£o da resposta
                if isinstance(final_output, str):
                    # Remove marcadores de c√≥digo desnecess√°rios
                    final_output = re.sub(r"^```(?:json|python|text)?\n?", "", final_output)
                    final_output = re.sub(r"\n?```$", "", final_output)
                    final_output = final_output.strip()
                    
                    # Formata√ß√£o especial para JSON estruturado
                    if final_output.startswith(('{', '[')):
                        try:
                            parsed_json = json.loads(final_output)
                            # Se for um resultado estruturado, format√°-lo melhor
                            if isinstance(parsed_json, dict):
                                formatted_output = ""
                                for key, value in parsed_json.items():
                                    if isinstance(value, dict):
                                        formatted_output += f"\n## {key.replace('_', ' ').title()}\n"
                                        for subkey, subvalue in value.items():
                                            formatted_output += f"**{subkey}:** {subvalue}\n"
                                    else:
                                        formatted_output += f"**{key.replace('_', ' ').title()}:** {value}\n"
                                final_output = formatted_output
                            else:
                                final_output = f"```json\n{json.dumps(parsed_json, ensure_ascii=False, indent=2)}\n```"
                        except json.JSONDecodeError:
                            pass


                # Mostrar resposta formatada
                st.markdown(final_output)
                
                # Verificar e mostrar gr√°ficos matplotlib
                if plt.get_fignums():
                    st.pyplot(plt.gcf())
                    plt.clf()
                
                # Adicionar resposta ao hist√≥rico
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": final_output
                })
                
                # Mostrar informa√ß√µes adicionais se a an√°lise foi extensa
                if len(final_output) > 500:
                    st.success("‚úÖ An√°lise EDA completa realizada!")
                    
                    # Sugerir pr√≥ximos passos
                    st.info("""
                    üí° **Pr√≥ximos passos sugeridos:**
                    - Explore aspectos espec√≠ficos que chamaram aten√ß√£o
                    - Pe√ßa an√°lises de correla√ß√£o mais detalhadas  
                    - Solicite gr√°ficos espec√≠ficos para vari√°veis de interesse
                    - Pe√ßa conclus√µes e insights acion√°veis
                    """)
                
                # Informa√ß√µes de debug (expans√≠vel)
                with st.expander("üîç Detalhes da Execu√ß√£o EDA", expanded=False):
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.subheader("üìù An√°lise Solicitada")
                        st.code(prompt, language="text")
                        
                        st.subheader("‚öôÔ∏è Configura√ß√£o do Sistema")
                        st.json({
                            "dataset": st.session_state.dataset_name,
                            "linhas": df.shape[0],
                            "colunas": df.shape[1],
                            "modelo": Settings.LLM_MODEL,
                            "temperatura": 0,
                            "mem√≥ria_chat": len(st.session_state.messages),
                            "tempo_sess√£o": f"{(datetime.now() - st.session_state.session_start).seconds}s"
                        })
                    
                    with col2:
                        st.subheader("üîÑ Resultados Intermedi√°rios")
                        intermediate = response_data.get("intermediate_results", {})
                        if intermediate:
                            st.json(intermediate)
                        else:
                            st.info("Processamento direto sem etapas intermedi√°rias")
                        
                        st.subheader("üìä An√°lise da Resposta")
                        response_stats = {
                            "tamanho_resposta": len(final_output),
                            "tipo_an√°lise": "Complexa" if len(final_output) > 500 else "Simples",
                            "gr√°ficos_gerados": len(plt.get_fignums()) if plt.get_fignums() else 0,
                            "formato": "JSON estruturado" if final_output.startswith(('{', '[')) else "Texto natural"
                        }
                        st.json(response_stats)
                
            except Exception as e:
                # Tratamento robusto de erros
                error_msg = f"‚ùå **Erro na an√°lise EDA**\n\n`{str(e)}`"
                st.error("Ops! Algo deu errado durante a an√°lise dos dados.")
                
                # Adicionar erro ao hist√≥rico
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": f"Erro na an√°lise: {str(e)}"
                })
                
                # Debug detalhado do erro
                with st.expander("üêõ Informa√ß√µes de Debug"):
                    st.code(f"Tipo do erro: {type(e).__name__}")
                    st.code(f"Mensagem: {str(e)}")
                    st.code("Traceback:")
                    st.code(traceback.format_exc())
                    
                    st.write("**Contexto:**")
                    st.write(f"- Dataset: {st.session_state.dataset_name}")
                    st.write(f"- Shape: {df.shape}")
                    st.write(f"- Consulta: {prompt}")
                
                # Sugest√µes de solu√ß√£o
                st.info("""
                üí° **Poss√≠veis solu√ß√µes:**
                - Tente reformular sua pergunta de forma mais espec√≠fica
                - Verifique se o dataset foi carregado corretamente
                - Para datasets muito grandes, tente an√°lises mais focadas
                - Recarregue a p√°gina se o problema persistir
                """)

# =============================================================================
# CONTROLES E UTILIT√ÅRIOS - APENAS SE HOUVER DATASET
# =============================================================================

if not df.empty:
    st.divider()
    st.subheader("üõ†Ô∏è Controles do Sistema")

    col1, col2, col3, col4, col5 = st.columns(5)

    with col1:
        if st.button("üóëÔ∏è Limpar Chat", width="stretch"):
            st.session_state.messages = []
            st.success("Chat limpo!")
            st.rerun()

    with col2:
        if st.button("üîÑ Resetar Sistema", width="stretch"):
            st.cache_resource.clear()
            st.cache_data.clear()
            st.session_state.messages = []
            st.session_state.analysis_history = []
            st.session_state.total_queries = 0
            st.success("Sistema resetado!")
            st.rerun()

    with col3:
        # Exportar an√°lises
        if st.session_state.messages and st.button("üì• Exportar EDA", width="stretch"):
            eda_export = {
                "dataset_info": {
                    "name": st.session_state.dataset_name,
                    "shape": df.shape,
                    "columns": df.columns.tolist(),
                    "dtypes": df.dtypes.astype(str).to_dict()
                },
                "session_info": {
                    "timestamp": datetime.now().isoformat(),
                    "total_queries": st.session_state.total_queries,
                    "duration_seconds": (datetime.now() - st.session_state.session_start).seconds,
                    "analysis_count": len(st.session_state.analysis_history)
                },
                "chat_history": st.session_state.messages,
                "analysis_history": [
                    {
                        "timestamp": h["timestamp"].isoformat(),
                        "query": h["query"],
                        "dataset": h["dataset"]
                    } for h in st.session_state.analysis_history
                ]
            }
            
            st.download_button(
                label="‚¨áÔ∏è Download Relat√≥rio EDA",
                data=json.dumps(eda_export, ensure_ascii=False, indent=2),
                file_name=f"eda_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                width="stretch"
            )

    with col4:
        # Sum√°rio do dataset
        if st.button("üìã Info Dataset", width="stretch"):
            st.info(f"""
            **üìä {st.session_state.dataset_name}**
            
            **Estrutura:**
            - Linhas: {df.shape[0]:,}
            - Colunas: {df.shape[1]}
            - Mem√≥ria: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB
            
            **Tipos:**
            - Num√©ricas: {len(df.select_dtypes(include=['number']).columns)}
            - Categ√≥ricas: {len(df.select_dtypes(include=['object']).columns)}
            
            **Qualidade:**
            - Nulos: {df.isnull().sum().sum():,}
            - Duplicatas: {df.duplicated().sum():,}
            """)

    with col5:
        # Hist√≥rico de an√°lises
        if st.session_state.analysis_history and st.button("üìà Hist√≥rico", width="stretch"):
            st.write("**üïí Hist√≥rico de An√°lises:**")
            for i, analysis in enumerate(st.session_state.analysis_history[-5:], 1):
                st.write(f"{i}. *{analysis['timestamp'].strftime('%H:%M')}* - {analysis['query'][:50]}...")

# =============================================================================
# GUIA DE USO PARA EDA - APENAS SE HOUVER DATASET
# =============================================================================

if not df.empty:
    with st.expander("üìñ Guia Completo de EDA - Atendendo aos Requisitos da Banca", expanded=False):
        
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "üìã Descri√ß√£o dos Dados",
            "üìà Padr√µes e Tend√™ncias", 
            "üö® Detec√ß√£o de Outliers",
            "üîó Rela√ß√µes entre Vari√°veis",
            "üß† Conclus√µes Inteligentes"
        ])
        
        with tab1:
            st.markdown("""
            ## üìä Descri√ß√£o dos Dados
            
            **Perguntas que voc√™ pode fazer:**
            
            ### Tipos de Dados:
            - "Quais s√£o os tipos de dados (num√©ricos, categ√≥ricos)?"
            - "Mostre a estrutura do dataset"
            - "Descreva as caracter√≠sticas de cada coluna"
            
            ### Distribui√ß√µes:
            - "Qual a distribui√ß√£o de cada vari√°vel?"
            - "Crie histogramas das vari√°veis num√©ricas"
            - "Mostre a distribui√ß√£o da vari√°vel [nome]"
            
            ### Intervalos e Estat√≠sticas:
            - "Qual o intervalo de cada vari√°vel (m√≠nimo, m√°ximo)?"
            - "Quais s√£o as medidas de tend√™ncia central?"
            - "Calcule m√©dia, mediana para todas as vari√°veis"
            - "Qual a variabilidade dos dados (desvio padr√£o, vari√¢ncia)?"
            """)
        
        with tab2:
            st.markdown("""
            ## üìà Identifica√ß√£o de Padr√µes e Tend√™ncias
            
            **An√°lises temporais:**
            - "Existem padr√µes temporais nos dados?"
            - "Analise a evolu√ß√£o temporal da vari√°vel Time"
            - "Mostre tend√™ncias ao longo do tempo"
            
            **Frequ√™ncias:**
            - "Quais os valores mais frequentes?"
            - "Identifique valores menos frequentes"
            - "Analise a distribui√ß√£o de frequ√™ncias"
            
            **Agrupamentos:**
            - "Existem agrupamentos (clusters) nos dados?"
            - "Identifique padr√µes de agrupamento"
            - "Analise segmenta√ß√£o natural dos dados"
            """)
        
        with tab3:
            st.markdown("""
            ## üö® Detec√ß√£o de Anomalias (Outliers)
            
            **Identifica√ß√£o:**
            - "Existem valores at√≠picos nos dados?"
            - "Detecte outliers em todas as vari√°veis"
            - "Mostre boxplots para identificar anomalias"
            
            **An√°lise de Impacto:**
            - "Como esses outliers afetam a an√°lise?"
            - "Qual o impacto dos outliers nas estat√≠sticas?"
            
            **Tratamento:**
            - "Os outliers podem ser removidos?"
            - "Sugira tratamento para valores at√≠picos"
            - "Analise se outliers devem ser investigados"
            """)
        
        with tab4:
            st.markdown("""
            ## üîó Rela√ß√µes entre Vari√°veis
            
            **Correla√ß√µes:**
            - "Como as vari√°veis est√£o relacionadas?"
            - "Existe correla√ß√£o entre as vari√°veis?"
            - "Crie matriz de correla√ß√£o"
            - "Mostre heatmap de correla√ß√µes"
            
            **Visualiza√ß√µes:**
            - "Crie gr√°ficos de dispers√£o entre vari√°veis"
            - "Mostre rela√ß√µes atrav√©s de scatter plots"
            - "Analise tabelas cruzadas"
            
            **Influ√™ncias:**
            - "Quais vari√°veis t√™m maior influ√™ncia?"
            - "Identifique vari√°veis mais importantes"
            - "Analise rela√ß√£o com a vari√°vel target"
            """)
        
        with tab5:
            st.markdown("""
            ## üß† Conclus√µes Inteligentes
            
            **S√≠ntese Completa:**
            - "Quais conclus√µes voc√™ obteve dos dados?"
            - "Resuma os principais insights"
            - "Gere relat√≥rio executivo"
            
            **Insights Acion√°veis:**
            - "Que a√ß√µes voc√™ recomenda baseado na an√°lise?"
            - "Quais s√£o os pr√≥ximos passos?"
            - "Identifique oportunidades nos dados"
            
            **An√°lise Preditiva:**
            - "Execute an√°lise completa de machine learning"
            - "Quais modelos s√£o mais adequados?"
            - "Avalie potencial preditivo dos dados"
            """)

# =============================================================================
# EXEMPLOS ESPEC√çFICOS PARA DATASETS - APENAS SE HOUVER DADOS
# =============================================================================

if not df.empty:
    
    if "credit" in st.session_state.dataset_name.lower() or "fraud" in st.session_state.dataset_name.lower():
        st.info("""
        üí≥ **Exemplos espec√≠ficos para Credit Card Fraud:**
        
        - "Analise a distribui√ß√£o de fraudes vs transa√ß√µes normais"
        - "Qual a rela√ß√£o entre Amount e Class?"
        - "Existem padr√µes temporais nas fraudes?"
        - "Como as vari√°veis V1-V28 (PCA) se relacionam com fraudes?"
        - "Detecte outliers que podem indicar fraudes"
        - "Crie modelos de machine learning para detectar fraudes"
        """)
    else:
        st.info(f"""
        üîç **Exemplos espec√≠ficos para seu dataset ({st.session_state.dataset_name}):**
        
        - "Fa√ßa uma an√°lise explorat√≥ria completa"
        - "Identifique padr√µes e tend√™ncias nos dados"
        - "Detecte outliers e anomalias"
        - "Analise correla√ß√µes entre vari√°veis"
        - "Gere insights e conclus√µes"
        """)

# =============================================================================
# INSTRU√á√ïES INICIAIS - APENAS SE N√ÉO HOUVER DATASET
# =============================================================================

if df.empty:
    st.divider()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìö Como Funciona")
        st.markdown("""
        **1. Carregue seus dados** üìÅ
        - Fa√ßa upload de qualquer arquivo CSV
        - Ou use nosso dataset de exemplo (Credit Card Fraud)
        
        **2. Fa√ßa perguntas naturais** üí¨
        - "Quais s√£o os tipos de dados?"
        - "Mostre a distribui√ß√£o das vari√°veis"
        - "Existem outliers nos dados?"
        
        **3. Receba an√°lises inteligentes** üß†
        - Gr√°ficos autom√°ticos
        - Insights acion√°veis
        - Conclus√µes detalhadas
        """)
    
    with col2:
        st.subheader("üéØ Principais Recursos")
        st.markdown("""
        **An√°lise Autom√°tica** üîç
        - Detec√ß√£o de tipos de dados
        - Estat√≠sticas descritivas
        - Identifica√ß√£o de padr√µes
        
        **Visualiza√ß√µes** üìä
        - Histogramas e boxplots
        - Correla√ß√µes e heatmaps
        - Gr√°ficos personalizados
        
        **Insights Avan√ßados** üöÄ
        - Detec√ß√£o de outliers
        - Machine Learning
        - Recomenda√ß√µes pr√°ticas
        """)


# =============================================================================
# RODAP√â
# =============================================================================

st.divider()
st.markdown(
    """
    <div style='text-align: center; color: #666; font-size: 0.8em;'>
        üéì <strong>Sistema EDA Gen√©rico - Atividade Banca Examinadora</strong><br>
        ‚úÖ Suporte completo a qualquer CSV ‚Ä¢ üìä EDA Automatizada ‚Ä¢ ü§ñ IA Integrada ‚Ä¢ üß† Conclus√µes Inteligentes<br>
        üî¨ Atende todos os requisitos: Descri√ß√£o ‚Ä¢ Padr√µes ‚Ä¢ Outliers ‚Ä¢ Correla√ß√µes ‚Ä¢ Insights
    </div>
    """, 
    unsafe_allow_html=True
)


import pandas as pd
import matplotlib.pyplot as plt
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain.tools import Tool
from typing import Dict, Any
import json

# Import das ferramentas de ML
from src.ml.ml_tools import (
    analyze_data_for_ml, 
    train_ml_models, 
    create_ml_comparison_plots,
    DataPreprocessor,
    ModelTrainer,
    ModelEvaluator,
    ML_AVAILABLE
)


def create_ml_analysis_tool(df: pd.DataFrame):
    """Cria ferramenta de an√°lise de dados para ML"""
    def ml_data_analysis(query: str) -> str:
        """Analisa dados para prepara√ß√£o de Machine Learning"""
        try:
            result = analyze_data_for_ml(df)
            print(f"DEBUG ML data Analisis Tool: {result}")
            return result
        except Exception as e:
            return f"Erro na an√°lise ML: {str(e)}"
    
    return Tool(
        name="analise_dados_ml",
        func=ml_data_analysis,
        description="Analisa dados para Machine Learning - qualidade, tipos, missing values, distribui√ß√µes"
    )


def create_model_training_tool(df: pd.DataFrame):
    """Cria ferramenta de treinamento de modelos"""
    def train_models(query: str) -> str:
        """Treina m√∫ltiplos modelos de ML"""
        try:
            # Extrair coluna target da query (implementa√ß√£o simples)
            words = query.lower().split()
            
            # Procurar por indica√ß√µes da coluna target
            target_column = None
            possible_targets = []
            
            # Palavras-chave que indicam target
            target_keywords = ["target", "classe", "class", "label", "objetivo", "prever", "predizer"]
            
            # Procurar colunas mencionadas na query
            for col in df.columns:
                if col.lower() in query.lower():
                    possible_targets.append(col)
            
            # Procurar por padr√µes comuns
            for word in words:
                if word in target_keywords:
                    idx = words.index(word)
                    if idx + 1 < len(words):
                        potential_target = words[idx + 1]
                        for col in df.columns:
                            if col.lower() == potential_target or potential_target in col.lower():
                                target_column = col
                                break
            
            # Se n√£o encontrou, usar a primeira coluna candidata
            if not target_column and possible_targets:
                target_column = possible_targets[0]
            
            # Fallback: usar a √∫ltima coluna (conven√ß√£o comum)
            if not target_column:
                target_column = df.columns[-1]
            result = train_ml_models(df, target_column)
            print(f"DEBUG Train Models : {result}")
            return result
            
        except Exception as e:
            return f"Erro no treinamento: {str(e)}"
    
    return Tool(
        name="treinar_modelos_ml",
        func=train_models,
        description="Treina m√∫ltiplos modelos de Machine Learning e compara performance"
    )


def create_ml_visualization_tool(df: pd.DataFrame):
    """Cria ferramenta de visualiza√ß√£o ML"""
    def create_ml_plots(query: str) -> str:
        """Cria gr√°ficos de compara√ß√£o de modelos"""
        try:
            # L√≥gica similar para extrair target
            target_column = df.columns[-1]  # Simplificado para exemplo
            
            words = query.lower().split()
            for col in df.columns:
                if col.lower() in query.lower():
                    target_column = col
                    break
            
            fig = create_ml_comparison_plots(df, target_column)
            return "Gr√°fico de compara√ß√£o de modelos ML criado com sucesso"
            
        except Exception as e:
            return f"Erro na cria√ß√£o de gr√°ficos ML: {str(e)}"
    
    return Tool(
        name="graficos_comparacao_ml",
        func=create_ml_plots,
        description="Cria gr√°ficos de compara√ß√£o de performance entre modelos de ML"
    )


def create_ml_recommendations_tool(df: pd.DataFrame):
    """Cria ferramenta de recomenda√ß√µes ML"""
    def ml_recommendations(query: str) -> str:
        """Fornece recomenda√ß√µes baseadas na an√°lise dos dados"""
        try:
            preprocessor = DataPreprocessor()
            analysis = preprocessor.analyze_data_quality(df)
            
            recommendations = []
            print(f"DEBUG ML Recommendations: {analysis}")
            # An√°lise de qualidade dos dados
            missing_total = sum(analysis["missing_values"].values())
            if missing_total > 0:
                recommendations.append(f"‚ö†Ô∏è Encontrados {missing_total} valores faltantes. Considere estrat√©gias de imputa√ß√£o.")
            
            # An√°lise de balanceamento (para colunas categ√≥ricas)
            if analysis["categorical_columns"]:
                for col in analysis["categorical_columns"]:
                    unique_count = df[col].nunique()
                    if unique_count == 2:
                        value_counts = df[col].value_counts()
                        ratio = value_counts.min() / value_counts.max()
                        if ratio < 0.3:
                            recommendations.append(f"‚öñÔ∏è Coluna '{col}' est√° desbalanceada (ratio: {ratio:.2f}). Considere t√©cnicas de balanceamento.")
            
            # Recomenda√ß√µes de modelos baseado no tipo de dados
            numeric_cols = len(analysis["numeric_columns"])
            categorical_cols = len(analysis["categorical_columns"])
            
            if numeric_cols > categorical_cols:
                recommendations.append("üìä Dataset com predomin√¢ncia num√©rica. Modelos recomendados: Random Forest, XGBoost, SVM.")
            else:
                recommendations.append("üè∑Ô∏è Dataset com muitas vari√°veis categ√≥ricas. Considere encoding adequado e modelos como Random Forest.")
            
            # An√°lise de tamanho
            n_samples = analysis["shape"][0]
            if n_samples < 1000:
                recommendations.append("üìè Dataset pequeno (<1000 amostras). Considere cross-validation e modelos menos complexos.")
            elif n_samples > 100000:
                recommendations.append("üìà Dataset grande (>100k amostras). Considere modelos escal√°veis como XGBoost ou t√©cnicas de sampling.")
            
            # An√°lise de dimensionalidade
            n_features = analysis["shape"][1]
            if n_features > n_samples:
                recommendations.append("üîç Mais features que amostras. Considere redu√ß√£o de dimensionalidade (PCA) ou regulariza√ß√£o.")
            
            # An√°lise de mem√≥ria
            if analysis["memory_usage_mb"] > 1000:
                recommendations.append("üíæ Dataset usa muita mem√≥ria (>1GB). Considere otimiza√ß√£o de tipos de dados ou processamento em chunks.")
            
            result = {
                "data_summary": {
                    "samples": n_samples,
                    "features": n_features,
                    "numeric_features": numeric_cols,
                    "categorical_features": categorical_cols,
                    "missing_values": missing_total,
                    "memory_usage_mb": analysis["memory_usage_mb"]
                },
                "recommendations": recommendations,
                "suggested_workflow": [
                    "1. üîç An√°lise explorat√≥ria completa",
                    "2. üßπ Limpeza e tratamento de missing values",
                    "3. üîÑ Encoding de vari√°veis categ√≥ricas",
                    "4. ‚öñÔ∏è Verificar balanceamento das classes",
                    "5. üìè Normaliza√ß√£o/padroniza√ß√£o dos dados",
                    "6. ü§ñ Treinamento de m√∫ltiplos modelos",
                    "7. üìä Avalia√ß√£o e compara√ß√£o de performance",
                    "8. üéØ Otimiza√ß√£o de hiperpar√¢metros do melhor modelo"
                ]
            }
            print(f"DEBUG: {json.dumps(result, ensure_ascii=False, indent=2)}")
            return json.dumps(result, ensure_ascii=False, indent=2)
            
        except Exception as e:
            return f"Erro nas recomenda√ß√µes ML: {str(e)}"
    
    return Tool(
        name="recomendacoes_ml",
        func=ml_recommendations,
        description="Fornece recomenda√ß√µes e insights para projetos de Machine Learning baseado nos dados"
    )


def agente_machine_learning(llm: BaseChatModel, df: pd.DataFrame) -> AgentExecutor:
    """
    Agente especialista em Machine Learning
    """
    # Verificar disponibilidade das bibliotecas ML
    if not ML_AVAILABLE:
        # Criar ferramenta de aviso
        def ml_warning(query: str) -> str:
            return """
            ‚ö†Ô∏è BIBLIOTECAS DE MACHINE LEARNING N√ÉO DISPON√çVEIS
            
            Para usar as funcionalidades de ML, instale as depend√™ncias:
            
            pip install scikit-learn xgboost imbalanced-learn
            
            Funcionalidades dispon√≠veis ap√≥s instala√ß√£o:
            - An√°lise de qualidade dos dados
            - Treinamento autom√°tico de m√∫ltiplos modelos
            - Compara√ß√£o de performance
            - Otimiza√ß√£o de hiperpar√¢metros
            - Visualiza√ß√µes de compara√ß√£o
            - Recomenda√ß√µes personalizadas
            """
        
        tools = [Tool(
            name="aviso_ml",
            func=ml_warning,
            description="Informa sobre a necessidade de instalar bibliotecas ML"
        )]
    else:
        # Criar todas as ferramentas ML
        tools = [
            create_ml_analysis_tool(df),
            create_model_training_tool(df),
            create_ml_visualization_tool(df),
            create_ml_recommendations_tool(df)
        ]
    
    prompt = ChatPromptTemplate.from_messages([
        SystemMessagePromptTemplate.from_template(
            """Voc√™ √© um especialista em Machine Learning e Data Science.

SUAS CAPACIDADES:
- An√°lise de qualidade de dados para ML
- Treinamento autom√°tico de m√∫ltiplos modelos
- Compara√ß√£o de performance entre modelos
- Recomenda√ß√µes baseadas nas caracter√≠sticas dos dados
- Cria√ß√£o de visualiza√ß√µes de compara√ß√£o

TIPOS DE AN√ÅLISE QUE VOC√ä PODE FAZER:
1. üîç AN√ÅLISE DE DADOS: Qualidade, tipos, missing values, distribui√ß√µes
2. ü§ñ TREINAMENTO: M√∫ltiplos modelos (Random Forest, XGBoost, SVM, etc.)
3. üìä COMPARA√á√ÉO: M√©tricas de performance, gr√°ficos, rankings
4. üéØ RECOMENDA√á√ïES: Sugest√µes baseadas nos dados

WORKFLOW RECOMENDADO:
1. Sempre comece com an√°lise de dados
2. Identifique o tipo de problema (classifica√ß√£o/regress√£o)
3. Treine m√∫ltiplos modelos
4. Compare performances
5. Forne√ßa recomenda√ß√µes

IMPORTANTE:
- Sempre analise os dados antes de treinar modelos
- Explique os resultados de forma clara
- Forne√ßa insights acion√°veis
- Considere limita√ß√µes e sugest√µes de melhoria

Responda de forma did√°tica e orientada a resultados.
"""
        ),
        HumanMessagePromptTemplate.from_template("{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad")
    ])

    agente = create_tool_calling_agent(llm, tools, prompt)
    return AgentExecutor(
        agent=agente, 
        tools=tools, 
        verbose=True,
        handle_parsing_errors=True,
        return_intermediate_steps=True
    )


def agente_ml_avancado(llm: BaseChatModel, df: pd.DataFrame) -> AgentExecutor:
    """
    Vers√£o avan√ßada do agente ML com funcionalidades extras
    """
    def advanced_ml_pipeline(query: str) -> str:
        """Pipeline completo de ML"""
        try:
            if not ML_AVAILABLE:
                return "Bibliotecas ML n√£o dispon√≠veis. Instale: pip install scikit-learn xgboost imbalanced-learn"
            
            # Detectar coluna target automaticamente
            target_col = None
            
            # Estrat√©gias para detectar target:
            # 1. Procurar palavras-chave na query
            query_lower = query.lower()
            for col in df.columns:
                if col.lower() in query_lower:
                    target_col = col
                    break
            
            # 2. Procurar colunas com nomes t√≠picos de target
            if not target_col:
                target_names = ['target', 'class', 'label', 'y', 'outcome', 'result']
                for col in df.columns:
                    if col.lower() in target_names:
                        target_col = col
                        break
            
            # 3. Usar a √∫ltima coluna (conven√ß√£o)
            if not target_col:
                target_col = df.columns[-1]
            
            # Executar pipeline completo
            results = {
                "1_data_analysis": json.loads(analyze_data_for_ml(df)),
                "2_model_training": json.loads(train_ml_models(df, target_col)),
                "3_recommendations": "Pipeline completo executado com sucesso"
            }
            print(f"DEBUG Advanced ml Pipeline: {json.dumps(results, ensure_ascii=False, indent=2)}")
            return json.dumps(results, ensure_ascii=False, indent=2)
            
        except Exception as e:
            return f"Erro no pipeline ML: {str(e)}"
    
    # Ferramentas b√°sicas + pipeline avan√ßado
    tools = []
    
    if ML_AVAILABLE:
        tools.extend([
            create_ml_analysis_tool(df),
            create_model_training_tool(df),
            create_ml_visualization_tool(df),
            create_ml_recommendations_tool(df),
            Tool(
                name="pipeline_ml_completo",
                func=advanced_ml_pipeline,
                description="Executa pipeline completo de ML: an√°lise + treinamento + recomenda√ß√µes"
            )
        ])
    else:
        tools.append(Tool(
            name="aviso_ml",
            func=lambda x: "Bibliotecas ML n√£o dispon√≠veis. Instale as depend√™ncias necess√°rias.",
            description="Aviso sobre bibliotecas ML"
        ))
    
    prompt = ChatPromptTemplate.from_messages([
        SystemMessagePromptTemplate.from_template(
            """Voc√™ √© um Data Scientist s√™nior especialista em Machine Learning.

MISS√ÉO: Automatizar completamente projetos de ML, desde an√°lise at√© recomenda√ß√µes.

FERRAMENTAS DISPON√çVEIS:
üîç analise_dados_ml: An√°lise detalhada da qualidade dos dados
ü§ñ treinar_modelos_ml: Treinamento autom√°tico de m√∫ltiplos modelos
üìä graficos_comparacao_ml: Visualiza√ß√µes de performance
üéØ recomendacoes_ml: Insights e sugest√µes personalizadas
‚ö° pipeline_ml_completo: Pipeline end-to-end automatizado

ABORDAGEM:
1. Para an√°lises r√°pidas: use pipeline_ml_completo
2. Para an√°lises detalhadas: use ferramentas individuais
3. Sempre forne√ßa contexto e interpreta√ß√£o dos resultados
4. Sugira pr√≥ximos passos e melhorias

FORMATO DE RESPOSTA:
- Seja claro e did√°tico
- Use emojis para organizar informa√ß√µes
- Forne√ßa insights acion√°veis
- Explique limita√ß√µes quando relevante

Voc√™ √© o especialista que transforma dados em insights valiosos!
"""
        ),
        HumanMessagePromptTemplate.from_template("{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad")
    ])

    agente = create_tool_calling_agent(llm, tools, prompt)
    return AgentExecutor(
        agent=agente, 
        tools=tools, 
        verbose=True,
        handle_parsing_errors=True,
        return_intermediate_steps=True
    )


# Teste local
if __name__ == "__main__":
    from langchain_groq import ChatGroq
    from src.agent.config_agent import Settings
    from src.data.bases import download_base
    
    # Carregar dados
    df = download_base()
    print("DataFrame carregado:", df.shape)
    
    # Inicializar LLM
    llm = ChatGroq(
        temperature=0, 
        # groq_api_key=Settings.GROQ_API_KEY, 
        model=Settings.LLM_MODEL
    )

    # Teste do agente ML
    executor = agente_machine_learning(llm, df)
    resultado = executor.invoke({"input": "Analise os dados e treine modelos de machine learning"})
    print("Resultado:", resultado.get("output"))